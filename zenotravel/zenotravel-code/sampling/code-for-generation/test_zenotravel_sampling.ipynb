{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import re\n",
    "import torch\n",
    "from transformers.generation import (\n",
    "    StoppingCriteria,\n",
    "    StoppingCriteriaList,\n",
    "    BeamSearchScorer,\n",
    "    LogitsProcessorList,\n",
    "    MaxLengthCriteria,\n",
    ")\n",
    "from transformers import LogitsProcessor\n",
    "import numpy as np\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from typing import Optional, Union, Tuple, List\n",
    "from datasets import load_from_disk\n",
    "from tqdm import tqdm\n",
    "from transformers import GPT2LMHeadModel, GenerationConfig\n",
    "from transformers import HfArgumentParser\n",
    "import os\n",
    "import sys\n",
    "from dataclasses import dataclass, field\n",
    "from datasets import Dataset\n",
    "import pandas as pd\n",
    "import os\n",
    "import json\n",
    "import time\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Generazione con zenotravel e greedy\n",
      "### Generazione con config.json\n",
      "{\n",
      "    \"domain\": \"zenotravel\",\n",
      "    \"model_dir\": \"./zenotravel-model/\",\n",
      "    \"dataset_dir\": \"./zenotravel-dataset-tesi/100\",\n",
      "    \"top_p\": 0.95,\n",
      "    \"do_sample\": true,\n",
      "    \"num_return_beams\": 10,\n",
      "    \"split_dataset\": \"test\",\n",
      "    \"output_dir\": \"zenotravel-generations-tesi/sampling/\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "domains = [\"zenotravel\"]\n",
    "\n",
    "for domain in domains:\n",
    "    for mode in [\"greedy\"]:\n",
    "        print(f\"### Generazione con {domain} e {mode}\")\n",
    "        path = f\"config.json\"\n",
    "        params = {\n",
    "            \"domain\": domain,\n",
    "            \"model_dir\": f\"./{domain}-model/\", \n",
    "            \"dataset_dir\": f\"./{domain}-dataset-tesi/100\",\n",
    "            \"top_p\": 0.95,\n",
    "            \"do_sample\": True,\n",
    "            \"num_return_beams\": 10,\n",
    "            \"split_dataset\": \"test\",\n",
    "            \"output_dir\": f\"{domain}-generations-tesi/sampling/\",\n",
    "        }\n",
    "        with open(path, \"w\") as file:\n",
    "            tmp = json.dumps(params, indent=4)\n",
    "            file.write(tmp)\n",
    "        with open(path, \"r\") as file:\n",
    "            # Carica il contenuto del file JSON in una variabile\n",
    "            data = json.load(file)\n",
    "        print(\"### Generazione con \" + path)\n",
    "        print(json.dumps(data, indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class PlanGeneratorArguments:\n",
    "    domain: str = field(\n",
    "        default=\"zenotravel\",\n",
    "        metadata={\"help\": \"The domain of the problems\"},\n",
    "    )\n",
    "    model_dir: str = field(\n",
    "        default=\"output_new_finetuning_more_batch/checkpoint-258502/\",\n",
    "        metadata={\"help\": \"The model directory\"},\n",
    "    )\n",
    "    dataset_dir: str = field(\n",
    "        default=\"data/ipc/zenotravel/random_new_correct_with_invariants_and_types/\",\n",
    "        metadata={\"help\": \"The dataset directory\"},\n",
    "    )\n",
    "    add_start: bool = field(\n",
    "        default=False,\n",
    "        metadata={\"help\": \"Add the start token to the prompt\"},\n",
    "    )\n",
    "    split_dataset: str = field(\n",
    "        default=\"validation\",\n",
    "        metadata={\"help\": \"The split of the dataset to use\"},\n",
    "    )\n",
    "    output_dir: str = field(\n",
    "        default=\"output_coverage_beam_search/\",\n",
    "        metadata={\"help\": \"The output directory\"},\n",
    "    )\n",
    "    # generation parameters\n",
    "    num_beams: int = field(\n",
    "        default=1,\n",
    "        metadata={\"help\": \"The number of beams to track\"},\n",
    "    )\n",
    "    num_return_beams: int = field(\n",
    "        default=1,\n",
    "        metadata={\"help\": \"The number of beams to return\"},\n",
    "    )\n",
    "    max_length: int = field(\n",
    "        default=2048,\n",
    "        metadata={\"help\": \"The maximum length of the generated plan\"},\n",
    "    )   \n",
    "    do_sample: bool = field(\n",
    "        default=False,\n",
    "        metadata={\"help\": \"If to sample the generation\"},\n",
    "    )\n",
    "    top_p: float = field(\n",
    "        default=1.0,\n",
    "        metadata={\"help\": \"The top_p parameter for the generation\"},\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./zenotravel-dataset-tesi/100 ./zenotravel-model/ zenotravel\n"
     ]
    }
   ],
   "source": [
    "# Create an instance of HfArgumentParser with your argument class\n",
    "parser = HfArgumentParser(PlanGeneratorArguments)\n",
    "\n",
    "(args,) = parser.parse_json_file(json_file=path)\n",
    "\n",
    "dataset_dir = args.dataset_dir\n",
    "model_path = args.model_dir\n",
    "domain = args.domain\n",
    "\n",
    "print(dataset_dir, model_path, domain)\n",
    "\n",
    "# check if exists\n",
    "if not os.path.exists(args.output_dir):\n",
    "    os.makedirs(args.output_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPT2LMHeadModel(\n",
       "  (transformer): GPT2Model(\n",
       "    (wte): Embedding(167, 768)\n",
       "    (wpe): Embedding(2048, 768)\n",
       "    (drop): Dropout(p=0.1, inplace=False)\n",
       "    (h): ModuleList(\n",
       "      (0-11): 12 x GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D(nf=2304, nx=768)\n",
       "          (c_proj): Conv1D(nf=768, nx=768)\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D(nf=3072, nx=768)\n",
       "          (c_proj): Conv1D(nf=768, nx=3072)\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=768, out_features=167, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "if \"ape\" in model_path:\n",
    "    model = GPT2_ape.from_pretrained(model_path)\n",
    "else:    \n",
    "    model = AutoModelForCausalLM.from_pretrained(model_path)\n",
    "model.to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation config loaded\n",
      "Model and Tokenizer loaded\n"
     ]
    }
   ],
   "source": [
    "generation_config = GenerationConfig(\n",
    "        num_beams=args.num_beams,\n",
    "        max_length=args.max_length,\n",
    "        do_sample=args.do_sample,\n",
    "        num_return_sequences=args.num_return_beams,\n",
    "        top_p=args.top_p,\n",
    ")\n",
    "print(\"Generation config loaded\")\n",
    "# print(\"Generation mode: \", generation_config.get_generation_mode()) # works only with transformers 4.40 +\n",
    "\n",
    "print(\"Model and Tokenizer loaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_actions_z = {}\n",
    "dict_predicates_z = {}\n",
    "dict_objects_z = {}\n",
    "\n",
    "dict_actions_z[\"board\"] = (\n",
    "    [\"person\", \"aircraft\", \"city\"],\n",
    "    [\"at 0 2\", \"at 1 2\"],\n",
    "    [\"in 0 1\"],\n",
    "    [\"at 0 2\"],\n",
    ")\n",
    "dict_actions_z[\"debark\"] = (\n",
    "    [\"person\", \"aircraft\", \"city\"],\n",
    "    [\"in 0 1\", \"at 1 2\"],\n",
    "    [\"at 0 2\"],\n",
    "    [\"in 0 1\"],\n",
    ")\n",
    "dict_actions_z[\"fly\"] = (\n",
    "    [\"aircraft\", \"city\", \"city\", \"flevel\", \"flevel\"],\n",
    "    [\"at 0 1\", \"fuel-level 0 3\", \"next 4 3\"],\n",
    "    [\"at 0 2\", \"fuel-level 0 4\"],\n",
    "    [\"at 0 1\", \"fuel-level 0 3\"],\n",
    ")\n",
    "dict_actions_z[\"zoom\"] = (\n",
    "    [\"aircraft\", \"city\", \"city\", \"flevel\", \"flevel\", \"flevel\"],\n",
    "    [\"at 0 1\", \"fuel-level 0 3\", \"next 4 3\", \"next 5 4\"],\n",
    "    [\"at 0 2\", \"fuel-level 0 5\"],\n",
    "    [\"at 0 1\", \"fuel-level 0 3\"],\n",
    ")\n",
    "dict_actions_z[\"refuel\"] = (\n",
    "    [\"aircraft\", \"city\", \"flevel\", \"flevel\"],\n",
    "    [\"fuel-level 0 2\", \"next 2 3\", \"at 0 1\"],\n",
    "    [\"fuel-level 0 3\"],\n",
    "    [\"fuel-level 0 2\"],\n",
    ")\n",
    "\n",
    "dict_predicates_z[\"at\"] = ([\"person\", \"aircraft\"], [\"city\"])\n",
    "dict_predicates_z[\"in\"] = ([\"person\"], [\"aircraft\"])\n",
    "dict_predicates_z[\"fuel-level\"] = ([\"flevel\"], [\"aircraft\"])\n",
    "dict_predicates_z[\"next\"] = ([\"flevel\"], [\"flevel\"])\n",
    "\n",
    "dict_predicates_z[\"aircraft\"] = [\"ob\"]\n",
    "dict_predicates_z[\"person\"] = [\"ob\"]\n",
    "dict_predicates_z[\"city\"] = [\"ob\"]\n",
    "dict_predicates_z[\"flevel\"] = [\"ob\"]\n",
    "\n",
    "dict_objects_z[\"aircraft\"] = [\"plane\"]\n",
    "dict_objects_z[\"person\"] = [\"person\"]\n",
    "dict_objects_z[\"city\"] = [\"city\"]\n",
    "dict_objects_z[\"flevel\"] = [\"fl\"]\n",
    "\n",
    "convert_action_z = {}\n",
    "convert_action_z[\"fuellevel\"] = \"fuel-level\"\n",
    "\n",
    "\n",
    "dict_actions_domain = {}\n",
    "dict_predicates_domain = {}\n",
    "dict_objects_domain = {}\n",
    "convert_action_domain = {}\n",
    "\n",
    "dict_actions_domain[\"zenotravel\"] = dict_actions_z\n",
    "dict_predicates_domain[\"zenotravel\"] = dict_predicates_z\n",
    "dict_objects_domain[\"zenotravel\"] = dict_objects_z\n",
    "convert_action_domain[\"zenotravel\"] = convert_action_z "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unite_actions(input, keywords, domain, separator=\"_\"):\n",
    "\n",
    "    for conversion in convert_action_domain[domain].keys():         \n",
    "        input = input.replace(conversion, convert_action_domain[domain][conversion])\n",
    "    list_to_unite = input.split()    \n",
    "    index_actions = []\n",
    "    for idx, token in enumerate(list_to_unite):\n",
    "        if token in keywords:            \n",
    "            index_actions.append(idx)    \n",
    "    index_actions.append(len(list_to_unite))\n",
    "    new_list = []\n",
    "    for i in range(len(index_actions) - 1):        \n",
    "        new_action = \" \".join(list_to_unite[index_actions[i] : index_actions[i + 1]])        \n",
    "        new_list.append(new_action.replace(\" \", separator))\n",
    "    return new_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# gestione file template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initial_state(path):\n",
    "    v=0\n",
    "    with open(path, \"r\") as f:         \n",
    "        righe = f.readlines()         \n",
    "              \n",
    "        inizio = False\n",
    "        state = \"\"\n",
    "\n",
    "        for riga in righe:\n",
    "            riga = riga.strip().replace(\"(\", \"\").replace(\")\", \"\")\n",
    "            if \"_100\" in path:\n",
    "                if \" - \" in riga:\n",
    "                    riga = riga.replace(\"-\", \" \").split()\n",
    "                    riga = riga[::-1]\n",
    "                    riga = \" \".join(riga)\n",
    "                    state += riga + \" \"\n",
    "            if riga == \"\":\n",
    "                inizio = False\n",
    "            if inizio:\n",
    "                state += riga + \" \"\n",
    "            if riga == \":init\":\n",
    "                inizio = True            \n",
    "\n",
    "    return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_goals(path):\n",
    "    goals = []\n",
    "    with open(path, \"r\") as f:\n",
    "        righe = f.readlines()\n",
    "        for riga in righe:\n",
    "            riga = riga.strip().replace(\"(\", \"\").replace(\")\", \"\").replace(\",\", \"\").lower()\n",
    "            goals.append(riga)\n",
    "    return goals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_actions(path):\n",
    "    actions = []\n",
    "    with open(path, \"r\") as f:\n",
    "        righe = f.readlines()\n",
    "        for riga in righe:\n",
    "            riga = riga.strip().replace(\"(\", \"\").replace(\")\", \"\").lower()\n",
    "            actions.append(riga)\n",
    "    return actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_starting_structures(plan, domain):\n",
    "\n",
    "    initial_states = (\n",
    "        plan[\"input\"].split(\"<|goals|>\")[0].strip().split(\"<|startofplan|>\")[1].strip()\n",
    "    )  \n",
    "       \n",
    "    goal_states = (\n",
    "        plan[\"input\"].split(\"<|goals|>\")[1].strip().split(\"<|actions|>\")[0].strip()\n",
    "    )\n",
    "    \n",
    "    initial_states = unite_actions(\n",
    "        initial_states, list(dict_predicates_domain[domain].keys()), domain\n",
    "    )\n",
    "    goal_states = unite_actions(\n",
    "        goal_states, list(dict_predicates_domain[domain].keys()), domain\n",
    "    )\n",
    "    if \"<|endofplan|>\" in plan[\"actions\"]:\n",
    "        actions = unite_actions(\n",
    "            plan[\"actions\"].split(\"<|endofplan|>\").strip(),\n",
    "            list(dict_actions_domain[domain].keys()),\n",
    "            domain,\n",
    "        )\n",
    "    else:\n",
    "        actions = unite_actions(\n",
    "            plan[\"actions\"], list(dict_actions_domain[domain].keys()), domain\n",
    "        )\n",
    "        \n",
    "    \n",
    "    dict_states = {}\n",
    "    dict_goals = {}\n",
    "    for init_state in initial_states:\n",
    "        dict_states[init_state] = True\n",
    "    for goal_state in goal_states:\n",
    "        if goal_state in initial_states:\n",
    "            dict_goals[goal_state] = True\n",
    "        else:\n",
    "            dict_goals[goal_state] = False    \n",
    "    return (dict_states, dict_goals, actions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rimuovi_numeri(stringa):\n",
    "    return \"\".join([i for i in stringa if not i.isdigit()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_goals(states, goal_states, domain):\n",
    "    all_goals_satisfied = True\n",
    "    goals_unsatisfied_list = []\n",
    "    goals_unsatisfied_list_nonumber = []\n",
    "    # print(goal_states)\n",
    "    for goal in goal_states.keys():\n",
    "        # print(\"Analizzo il goal \" + goal)\n",
    "        if goal not in states.keys():\n",
    "            goal_states[goal] = False\n",
    "            all_goals_satisfied = False\n",
    "            goals_unsatisfied_list.append(goal)\n",
    "            goals_unsatisfied_list_nonumber.append(rimuovi_numeri(goal))\n",
    "            # print(\"Il mio goal non è negli stati visti\")\n",
    "        elif states[goal] is False:\n",
    "            goal_states[goal] = False\n",
    "            all_goals_satisfied = False\n",
    "            goals_unsatisfied_list.append(goal)\n",
    "            goals_unsatisfied_list_nonumber.append(rimuovi_numeri(goal))\n",
    "            # print(\"Il mio goal è negli stati visti falso\")\n",
    "        else:\n",
    "            goal_states[goal] = True\n",
    "            # print(\"Il mio goal è negli stati visti vero\")\n",
    "    if all_goals_satisfied is True:\n",
    "        return (True, goal_states, \"goals_succesfull\")\n",
    "    else:\n",
    "        return (\n",
    "            False,\n",
    "            goal_states,\n",
    "            \"goals_not_succesfull\",\n",
    "            goals_unsatisfied_list_nonumber,\n",
    "            goals_unsatisfied_list,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def execute_action(states, action, domain):\n",
    "    # Return a Tuple\n",
    "    # in the first position the result True, False\n",
    "    # in the second position the next state if result is True or the current state if it is False\n",
    "    # in the third position the motivation of the wrong execution\n",
    "    # split my action, on position 0 the action, then the objects\n",
    "    # print(action)\n",
    "    splitted_action = action.split(\"_\")[0]  # prendo il nome della mia azione\n",
    "    try:\n",
    "        action_parameter = dict_actions_domain[domain][\n",
    "            splitted_action\n",
    "        ]  # verifico che l'azione esiste\n",
    "    except:\n",
    "        action_parameter = None\n",
    "    if action_parameter is None:\n",
    "        return (False, states, \"action_name_wrong\", splitted_action, action, \"\")\n",
    "    splitted_objects = action.split(\"_\")[\n",
    "        1:\n",
    "    ]  # ottengo il nome dei miei oggetti definiti nel mio problema\n",
    "    action_objects = action_parameter[0]  # ottengo gli oggetti accettati dall'azione\n",
    "    if len(action_objects) == len(\n",
    "        splitted_objects\n",
    "    ):  # verifico che gli oggetti siano in egual numero rispetto a quanti ne richiede la mia azione\n",
    "        for i in range(0, len(action_objects)):  # scorro i miei oggetti\n",
    "            obj_nonumber = \"\".join(\n",
    "                [j for j in splitted_objects[i] if not j.isdigit()]\n",
    "            )  # calcolo il mio nome dell'oggetto senza tener conto dei numeri\n",
    "            if (\n",
    "                obj_nonumber not in dict_objects_domain[domain][action_objects[i]]\n",
    "            ):  # verifico che l'oggetto si trovi nella lista di nomi possibili associata alla descrizione dell'azione\n",
    "                # print(\"Errore: \" + obj_nonumber + \" non è un oggetto valido per \" + action_objects[i])\n",
    "                # print(\"Gli oggetti validi sono: \" + str(dict_objects_domain[domain][action_objects[i]]))\n",
    "                return (\n",
    "                    False,\n",
    "                    states,\n",
    "                    \"object_name_wrong\",\n",
    "                    splitted_action,\n",
    "                    obj_nonumber,\n",
    "                    splitted_objects[i],\n",
    "                )\n",
    "    else:\n",
    "        return (\n",
    "            False,\n",
    "            states,\n",
    "            \"object_number_wrong\",\n",
    "            splitted_action,\n",
    "            len(action_objects),\n",
    "            len(splitted_objects),\n",
    "        )\n",
    "\n",
    "    action_prec = action_parameter[1]  # prendo le precondizioni della mia azione\n",
    "    violed_precondtion = False\n",
    "    violed_preconditions_list = []\n",
    "    violed_preconditions_list_nonumber = []\n",
    "    for prec in action_prec:  # scorro le mie precondizioni\n",
    "        prec_list = prec.split(\" \")\n",
    "        prec_parametrized = \"\" + prec_list[0]  # metto il mio predicato\n",
    "        for obj in prec_list[1:]:  # scorro gli oggetti della mia precondizione\n",
    "            prec_parametrized = (\n",
    "                prec_parametrized + \"_\" + splitted_objects[int(obj)]\n",
    "            )  # sostituisco gli oggetti generici ai miei oggetti del problema\n",
    "        if (\n",
    "            prec_parametrized not in states.keys()\n",
    "        ):  # controllo se la mia precondizione esiste come chiave del dizionario (se non esiste non è vera)\n",
    "            violed_precondtion = True\n",
    "            violed_preconditions_list.append(prec_parametrized)\n",
    "            violed_preconditions_list_nonumber.append(rimuovi_numeri(prec_parametrized))\n",
    "        elif (\n",
    "            states[prec_parametrized] is False\n",
    "        ):  # controllo che la mia precondizione sia vera per eseguire l'azione\n",
    "            violed_precondtion = True\n",
    "            violed_preconditions_list.append(prec_parametrized)\n",
    "            violed_preconditions_list_nonumber.append(rimuovi_numeri(prec_parametrized))\n",
    "        else:\n",
    "            pass\n",
    "    if violed_precondtion is True:\n",
    "        return (\n",
    "            False,\n",
    "            states,\n",
    "            \"violed_preconditions\",\n",
    "            violed_preconditions_list_nonumber,\n",
    "            violed_preconditions_list,\n",
    "            splitted_action,\n",
    "        )\n",
    "\n",
    "    # eseguo gli effetti negativi\n",
    "    action_neg = action_parameter[3]  # prendo i miei effetti negativi\n",
    "    for neg in action_neg:  # li scorro\n",
    "        neg_list = neg.split(\" \")\n",
    "        neg_parametrized = \"\" + neg_list[0]  # ottengo il mio predicato\n",
    "        for obj in neg_list[1:]:  # per ogni oggetto (rappresentato come indice)\n",
    "            neg_parametrized = (\n",
    "                neg_parametrized + \"_\" + splitted_objects[int(obj)]\n",
    "            )  # vado a sostituirlo col corrispettivo dell'azione in corso\n",
    "        states[neg_parametrized] = False  # cambio il valore nei miei stati\n",
    "        # print(\"ho reso falso \" + neg_parametrized)\n",
    "\n",
    "    # eseguo gli effetti additivi\n",
    "    action_plus = action_parameter[2]  # prendo i miei effetti additivi\n",
    "    for plus in action_plus:  # li scorro\n",
    "        plus_list = plus.split(\" \")\n",
    "        plus_parametrized = \"\" + plus_list[0]  # ottengo il mio predicato\n",
    "        for obj in plus_list[1:]:  # per ogni oggetto (rappresentato come indice)\n",
    "            plus_parametrized = (\n",
    "                plus_parametrized + \"_\" + splitted_objects[int(obj)]\n",
    "            )  # vado a sostituirlo col corrispettivo dell'azione in corso\n",
    "        states[plus_parametrized] = True  # cambio il valore nei miei stati\n",
    "        # print(\"ho reso vero \" + plus_parametrized)\n",
    "\n",
    "    return (True, states, \"action_succesfull\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_violated_preconditions(plan, domain):\n",
    "    init_structures = create_starting_structures(plan, domain)\n",
    "    init_state = init_structures[0]\n",
    "    goal_state = init_structures[1]\n",
    "    actions = init_structures[2]\n",
    "    if len(actions) == 0 and len(plan[\"actions\"]) != 0:\n",
    "        return True  # Il modello ha generato i token iniziali diversi da azioni (parole a caso)\n",
    "    # print(\"Actions \", actions)\n",
    "    result_goals = check_goals(init_state, goal_state, domain)\n",
    "    state = init_state\n",
    "    for action in actions:\n",
    "        result = execute_action(state, action, domain)\n",
    "        # print(\"Res action \", result)\n",
    "        if result[0] is True:\n",
    "            state = result[1]\n",
    "        else:\n",
    "            error_type = result[2]\n",
    "            if error_type == \"object_name_wrong\":\n",
    "                return True\n",
    "            elif error_type == \"object_number_wrong\":\n",
    "                if result[4] > result[5]:\n",
    "                    return False\n",
    "                else:\n",
    "                    return True\n",
    "            elif error_type == \"violed_preconditions\":\n",
    "                return True\n",
    "            elif error_type == \"action_name_wrong\":\n",
    "                return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_reward(plan, domain):    \n",
    "  \n",
    "    init_structures = create_starting_structures(plan, domain)\n",
    "    init_state = init_structures[0]\n",
    "    goal_state = init_structures[1]\n",
    "    actions = init_structures[2]\n",
    "\n",
    "    start = time.time()\n",
    "\n",
    "    result_goals = check_goals(init_state, goal_state, domain)\n",
    "    if result_goals[0] is True:\n",
    "        return 1\n",
    "    else:\n",
    "        pass\n",
    "    state = init_state\n",
    "    j = 0\n",
    "    for action in actions:\n",
    "        start_act = time.time()\n",
    "        result = execute_action(state, action, domain)\n",
    "        if result[0] is True:\n",
    "            # print(result[2])\n",
    "            state = result[1]\n",
    "            result_goals = check_goals(state, goal_state, domain)\n",
    "            if result_goals[0] is True:\n",
    "                return 1\n",
    "            else:\n",
    "                pass\n",
    "                # print(result_goals[2])\n",
    "        else:\n",
    "            result_goals = check_goals(state, goal_state, domain)\n",
    "            goals_satisfied = result_goals[1]\n",
    "            count = 0\n",
    "            n_goals = len(goals_satisfied.keys())\n",
    "            for goal in goals_satisfied.keys():\n",
    "                if goals_satisfied[goal] is True:\n",
    "                    count += 1\n",
    "            if check_violated_preconditions(plan, domain) is True:\n",
    "                return (count / n_goals) - 1\n",
    "            else:\n",
    "                return count / n_goals\n",
    "        j = j + 1\n",
    "        end_act = time.time()\n",
    "        # print(\"Ho impiegato per fare una azione: \" + str(end_act-start_act))\n",
    "\n",
    "    number_missing_actions = len(actions) - j\n",
    "    end = time.time()\n",
    "    # print(\"Ho impiegato \" + str(end-start))\n",
    "    goals_satisfied = result_goals[1]\n",
    "    count = 0\n",
    "    n_goals = len(goals_satisfied.keys())\n",
    "    for goal in goals_satisfied.keys():\n",
    "        if goals_satisfied[goal] is True:\n",
    "            count += 1\n",
    "    return count / n_goals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_problem(plan, domain):    \n",
    "   \n",
    "            \n",
    "    init_structures = create_starting_structures(plan, domain) # riporta i dizionari dei fluenti iniziali e dei fluenti obiettivo e l'inisieme delle azioni generate\n",
    "    init_state = init_structures[0]  # dizionario con tutti i fluenti iniziali con assocciato il valore true\n",
    "    goal_state = init_structures[1]  # dizionario con i fluenti obiettivo con associato il valore true o false in base ai fluenti iniziali\n",
    "    actions = init_structures[2]     # vettore contenente le azioni generate da planGPT\n",
    "    \n",
    "    start = time.time()\n",
    "\n",
    "    result_goals = check_goals(init_state, goal_state, domain)   \n",
    "        \n",
    "    if result_goals[0] is True:\n",
    "        return (result_goals[0], result_goals[1], result_goals[2], len(actions))\n",
    "        # print(result_goals[2])\n",
    "    else:\n",
    "        pass\n",
    "        # print(result_goals[2])\n",
    "\n",
    "    state = init_state    \n",
    "    j = 0\n",
    "    for action in actions:\n",
    "        start_act = time.time()\n",
    "        result = execute_action(state, action, domain)\n",
    "        if result[0] is True:\n",
    "            # print(result[2])\n",
    "            state = result[1]\n",
    "            result_goals = check_goals(state, goal_state, domain)\n",
    "            if result_goals[0] is True:\n",
    "                # print(result_goals[2])\n",
    "                j = j + 1\n",
    "                break\n",
    "            else:\n",
    "                pass\n",
    "                # print(result_goals[2])\n",
    "        else:\n",
    "            result_goals = check_goals(state, goal_state, domain)\n",
    "            return (\n",
    "                result[0],\n",
    "                result_goals[1],\n",
    "                result[2],\n",
    "                result[3],\n",
    "                result[4],\n",
    "                result[5],\n",
    "                j,\n",
    "            )\n",
    "            # print(result[2])\n",
    "            # print(result[1])\n",
    "            break\n",
    "        j = j + 1\n",
    "        end_act = time.time()\n",
    "        # print(\"Ho impiegato per fare una azione: \" + str(end_act-start_act))\n",
    "\n",
    "    number_missing_actions = len(actions) - j\n",
    "    end = time.time()\n",
    "    # print(\"Ho impiegato \" + str(end-start))\n",
    "    return (result_goals[0], result_goals[1], result_goals[2], number_missing_actions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# run 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 zenotravel_p004504_hyp=hyp-6_100\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[58], line 75\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39minference_mode():                \n\u001b[1;32m     74\u001b[0m     start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m---> 75\u001b[0m     generated \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     76\u001b[0m \u001b[43m        \u001b[49m\u001b[43mprompt_tokenized\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     77\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpad_token_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtokenizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meos_token_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     78\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     79\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     80\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     81\u001b[0m     end_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m     82\u001b[0m     delta_time \u001b[38;5;241m=\u001b[39m end_time \u001b[38;5;241m-\u001b[39m start_time\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/_contextlib.py:116\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 116\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/transformers/src/transformers/generation/utils.py:2228\u001b[0m, in \u001b[0;36mGenerationMixin.generate\u001b[0;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, **kwargs)\u001b[0m\n\u001b[1;32m   2220\u001b[0m     input_ids, model_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_expand_inputs_for_generation(\n\u001b[1;32m   2221\u001b[0m         input_ids\u001b[38;5;241m=\u001b[39minput_ids,\n\u001b[1;32m   2222\u001b[0m         expand_size\u001b[38;5;241m=\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39mnum_return_sequences,\n\u001b[1;32m   2223\u001b[0m         is_encoder_decoder\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mis_encoder_decoder,\n\u001b[1;32m   2224\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs,\n\u001b[1;32m   2225\u001b[0m     )\n\u001b[1;32m   2227\u001b[0m     \u001b[38;5;66;03m# 12. run sample (it degenerates to greedy search when `generation_config.do_sample=False`)\u001b[39;00m\n\u001b[0;32m-> 2228\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sample\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2229\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2230\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlogits_processor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprepared_logits_processor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2231\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstopping_criteria\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprepared_stopping_criteria\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2232\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2233\u001b[0m \u001b[43m        \u001b[49m\u001b[43msynced_gpus\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msynced_gpus\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2234\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstreamer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstreamer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2235\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2236\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2238\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m generation_mode \u001b[38;5;129;01min\u001b[39;00m (GenerationMode\u001b[38;5;241m.\u001b[39mBEAM_SAMPLE, GenerationMode\u001b[38;5;241m.\u001b[39mBEAM_SEARCH):\n\u001b[1;32m   2239\u001b[0m     \u001b[38;5;66;03m# 11. prepare beam search scorer\u001b[39;00m\n\u001b[1;32m   2240\u001b[0m     beam_scorer \u001b[38;5;241m=\u001b[39m BeamSearchScorer(\n\u001b[1;32m   2241\u001b[0m         batch_size\u001b[38;5;241m=\u001b[39mbatch_size,\n\u001b[1;32m   2242\u001b[0m         num_beams\u001b[38;5;241m=\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39mnum_beams,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2247\u001b[0m         max_length\u001b[38;5;241m=\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39mmax_length,\n\u001b[1;32m   2248\u001b[0m     )\n",
      "File \u001b[0;32m/transformers/src/transformers/generation/utils.py:3214\u001b[0m, in \u001b[0;36mGenerationMixin._sample\u001b[0;34m(self, input_ids, logits_processor, stopping_criteria, generation_config, synced_gpus, streamer, **model_kwargs)\u001b[0m\n\u001b[1;32m   3212\u001b[0m     is_prefill \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m   3213\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 3214\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m   3216\u001b[0m \u001b[38;5;66;03m# synced_gpus: don't waste resources running the code we don't need; kwargs must be updated before skipping\u001b[39;00m\n\u001b[1;32m   3217\u001b[0m model_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_model_kwargs_for_generation(\n\u001b[1;32m   3218\u001b[0m     outputs,\n\u001b[1;32m   3219\u001b[0m     model_kwargs,\n\u001b[1;32m   3220\u001b[0m     is_encoder_decoder\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mis_encoder_decoder,\n\u001b[1;32m   3221\u001b[0m )\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/transformers/src/transformers/models/gpt2/modeling_gpt2.py:1062\u001b[0m, in \u001b[0;36mGPT2LMHeadModel.forward\u001b[0;34m(self, input_ids, past_key_values, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, labels, use_cache, output_attentions, output_hidden_states, return_dict, **kwargs)\u001b[0m\n\u001b[1;32m   1054\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1055\u001b[0m \u001b[38;5;124;03mlabels (`torch.LongTensor` of shape `(batch_size, sequence_length)`, *optional*):\u001b[39;00m\n\u001b[1;32m   1056\u001b[0m \u001b[38;5;124;03m    Labels for language modeling. Note that the labels **are shifted** inside the model, i.e. you can set\u001b[39;00m\n\u001b[1;32m   1057\u001b[0m \u001b[38;5;124;03m    `labels = input_ids` Indices are selected in `[-100, 0, ..., config.vocab_size]` All labels set to `-100`\u001b[39;00m\n\u001b[1;32m   1058\u001b[0m \u001b[38;5;124;03m    are ignored (masked), the loss is only computed for labels in `[0, ..., config.vocab_size]`\u001b[39;00m\n\u001b[1;32m   1059\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1060\u001b[0m return_dict \u001b[38;5;241m=\u001b[39m return_dict \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39muse_return_dict\n\u001b[0;32m-> 1062\u001b[0m transformer_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransformer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1063\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1064\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1065\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1066\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtoken_type_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken_type_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1067\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1068\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1069\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1070\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1071\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1072\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1073\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1074\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1075\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1076\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1077\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m transformer_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m   1079\u001b[0m \u001b[38;5;66;03m# Set device for model parallelism\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/transformers/src/transformers/models/gpt2/modeling_gpt2.py:922\u001b[0m, in \u001b[0;36mGPT2Model.forward\u001b[0;34m(self, input_ids, past_key_values, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    910\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gradient_checkpointing_func(\n\u001b[1;32m    911\u001b[0m         block\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m,\n\u001b[1;32m    912\u001b[0m         hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    919\u001b[0m         output_attentions,\n\u001b[1;32m    920\u001b[0m     )\n\u001b[1;32m    921\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 922\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mblock\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    923\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    924\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlayer_past\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlayer_past\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    925\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    926\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    927\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    928\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    929\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    930\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    931\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    933\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    934\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_cache \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/transformers/src/transformers/models/gpt2/modeling_gpt2.py:404\u001b[0m, in \u001b[0;36mGPT2Block.forward\u001b[0;34m(self, hidden_states, layer_past, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, use_cache, output_attentions)\u001b[0m\n\u001b[1;32m    402\u001b[0m residual \u001b[38;5;241m=\u001b[39m hidden_states\n\u001b[1;32m    403\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mln_1(hidden_states)\n\u001b[0;32m--> 404\u001b[0m attn_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mattn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    405\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    406\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlayer_past\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlayer_past\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    407\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    408\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    409\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    410\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    411\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    412\u001b[0m attn_output \u001b[38;5;241m=\u001b[39m attn_outputs[\u001b[38;5;241m0\u001b[39m]  \u001b[38;5;66;03m# output_attn: a, present, (attentions)\u001b[39;00m\n\u001b[1;32m    413\u001b[0m outputs \u001b[38;5;241m=\u001b[39m attn_outputs[\u001b[38;5;241m1\u001b[39m:]\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/transformers/src/transformers/models/gpt2/modeling_gpt2.py:335\u001b[0m, in \u001b[0;36mGPT2Attention.forward\u001b[0;34m(self, hidden_states, layer_past, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, use_cache, output_attentions, **kwargs)\u001b[0m\n\u001b[1;32m    331\u001b[0m     attn_output, attn_weights \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_upcast_and_reordered_attn(\n\u001b[1;32m    332\u001b[0m         query_states, key_states, value_states, attention_mask, head_mask\n\u001b[1;32m    333\u001b[0m     )\n\u001b[1;32m    334\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 335\u001b[0m     attn_output, attn_weights \u001b[38;5;241m=\u001b[39m \u001b[43mattention_interface\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    336\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    337\u001b[0m \u001b[43m        \u001b[49m\u001b[43mquery_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    338\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkey_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    339\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvalue_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    340\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    341\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    342\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdropout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mattn_dropout\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mp\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    343\u001b[0m \u001b[43m        \u001b[49m\u001b[43mis_causal\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_causal\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    344\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    345\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    347\u001b[0m attn_output \u001b[38;5;241m=\u001b[39m attn_output\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m*\u001b[39mattn_output\u001b[38;5;241m.\u001b[39mshape[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m], \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mcontiguous()\n\u001b[1;32m    348\u001b[0m attn_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mc_proj(attn_output)\n",
      "File \u001b[0;32m/transformers/src/transformers/integrations/sdpa_attention.py:53\u001b[0m, in \u001b[0;36msdpa_attention_forward\u001b[0;34m(module, query, key, value, attention_mask, dropout, scaling, is_causal, **kwargs)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mjit\u001b[38;5;241m.\u001b[39mis_tracing() \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(is_causal, torch\u001b[38;5;241m.\u001b[39mTensor):\n\u001b[1;32m     51\u001b[0m     is_causal \u001b[38;5;241m=\u001b[39m is_causal\u001b[38;5;241m.\u001b[39mitem()\n\u001b[0;32m---> 53\u001b[0m attn_output \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunctional\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscaled_dot_product_attention\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[43m    \u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     56\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     57\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattn_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcausal_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     58\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdropout_p\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdropout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     59\u001b[0m \u001b[43m    \u001b[49m\u001b[43mscale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mscaling\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     60\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_causal\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_causal\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     61\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     62\u001b[0m attn_output \u001b[38;5;241m=\u001b[39m attn_output\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m)\u001b[38;5;241m.\u001b[39mcontiguous()\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m attn_output, \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "counter = 0\n",
    "last_generated = 0\n",
    "generation_output = []\n",
    "total_plans = 0\n",
    "tot_time = 0\n",
    "tot_skip = 0\n",
    "v=0\n",
    "\n",
    "for folder in os.listdir(dataset_dir):   \n",
    "    v+=1\n",
    "    print(v, folder)\n",
    "    cont=0\n",
    "    cont_action=0\n",
    "    for file in os.listdir(os.path.join(dataset_dir, folder)):\n",
    "        path = os.path.join(dataset_dir, folder, file)\n",
    "        if file == \"template.pddl\":\n",
    "            state = initial_state(path)                \n",
    "        elif file == \"hyps.dat\":\n",
    "            goals = get_goals(path) \n",
    "        elif file == \"obs.dat\":\n",
    "            actions = get_actions(path)  \n",
    "        elif file == \"real_hyp.dat\":\n",
    "            real_goal = get_goals(path)\n",
    "   \n",
    "    state = unite_actions(\n",
    "        state,\n",
    "        list(dict_predicates_domain[domain].keys()),\n",
    "        domain,\n",
    "    )\n",
    "    state = [x.replace(\"_\", \" \") for x in state]\n",
    "    state = sorted(state)\n",
    "    state = \" \".join(state)    \n",
    "    \n",
    "    for r_goal in real_goal:\n",
    "        r_goal = unite_actions(\n",
    "            r_goal,\n",
    "            list(dict_predicates_domain[domain].keys()),\n",
    "            domain,\n",
    "        )\n",
    "        r_goal = [x.replace(\"_\", \" \") for x in r_goal]\n",
    "        r_goal = sorted(r_goal)\n",
    "        r_goal = \" \".join(r_goal)\n",
    "    \n",
    "    prompts = []\n",
    "    prompts_tokenized = []\n",
    "    goals_sorted = []\n",
    "    for goal in goals:\n",
    "        goal = unite_actions(\n",
    "            goal,\n",
    "            list(dict_predicates_domain[domain].keys()),\n",
    "            domain,\n",
    "        )\n",
    "\n",
    "        goal = [x.replace(\"_\", \" \") for x in goal]\n",
    "        goal = sorted(goal)\n",
    "        goal = \" \".join(goal)\n",
    "        goals_sorted.append(goal)\n",
    "        prompt = state + \" <|goals|> \" + goal + \" <|actions|>\"\n",
    "        prompts.append(prompt)\n",
    "        prompt_tokenized = tokenizer(prompt, return_tensors=\"pt\", truncation=True, max_length=args.max_length)\n",
    "        prompt_tokenized = prompt_tokenized[\"input_ids\"].to(model.device)\n",
    "        prompts_tokenized.append(prompt_tokenized)\n",
    "        for action in actions:            \n",
    "            prompt = prompt + action + \" \"    \n",
    "            prompts.append(prompt)\n",
    "            prompt_tokenized = tokenizer(prompt, return_tensors=\"pt\", truncation=True, max_length=args.max_length)\n",
    "            prompt_tokenized = prompt_tokenized[\"input_ids\"].to(model.device)\n",
    "            prompts_tokenized.append(prompt_tokenized)    \n",
    "            \n",
    "    skip_number=0\n",
    "    for prompt_tokenized in prompts_tokenized: \n",
    "                  \n",
    "        with torch.inference_mode():                \n",
    "            start_time = time.time()\n",
    "            generated = model.generate(\n",
    "                prompt_tokenized,\n",
    "                pad_token_id=tokenizer.eos_token_id,\n",
    "                max_length=args.max_length,\n",
    "                generation_config=generation_config,\n",
    "            )\n",
    "            end_time = time.time()\n",
    "            delta_time = end_time - start_time\n",
    "            tot_time+=delta_time\n",
    "            \n",
    "        found_true = False\n",
    "        plans = []\n",
    "        for index, output_tokenized in enumerate(generated):\n",
    "            output = tokenizer.decode(output_tokenized)                 \n",
    "            inputs = output.split(\"<|actions|>\")[0]\n",
    "            plan = output.split(\"<|actions|>\")[1]\n",
    "            if \"<|endofplan|>\" in plan:        \n",
    "                plan = plan.split(\"<|endofplan|>\")[0]\n",
    "            plan = plan.replace(\"<|endofplan|>\", \"\")\n",
    "            plan = plan.replace(\"<|startofplan|>\", \"\")\n",
    "            plan = plan.replace(\"<|pad|>\", \"\")\n",
    "            p = {\"input\": inputs, \"actions\": plan}       \n",
    "            res = parse_problem(p, domain=domain)   \n",
    "            metric_goals_satisfated=calculate_reward(p,domain=domain)   \n",
    "            plans.append({\"plan\": plan, \"result\": res})  \n",
    "            if res[0] is True:\n",
    "                found_true = True\n",
    "                \n",
    "        if found_true is True:\n",
    "            counter += 1            \n",
    "        \n",
    "        actions_string = \" \".join(actions)             \n",
    "        \n",
    "        if r_goal == goals_sorted[cont]:  \n",
    "            true_goal = True                        \n",
    "        else:\n",
    "            true_goal = False\n",
    "            \n",
    "        generation_output.append(\n",
    "            {\n",
    "                \"name\": folder,\n",
    "                \"goal\": goals[cont],\n",
    "                \"input\": prompts[cont], #cont or cont_action\n",
    "                \"action\": prompts[cont_action].split(\"<|actions|>\")[1],\n",
    "                \"true_goal\": true_goal,\n",
    "                \"actions\": actions_string,\n",
    "                \"plans\": plans,\n",
    "                \"value of the metric goals satisfated\": metric_goals_satisfated,                \n",
    "                \"time\": format(delta_time, \".2f\"),\n",
    "            }\n",
    "        )  \n",
    "        cont_action+=1\n",
    "        if cont_action > len(actions):            \n",
    "            total_plans+=cont_action            \n",
    "            cont_action=0\n",
    "            cont+=1   \n",
    "    \n",
    "    # Save the last batch\n",
    "    with open(\n",
    "        os.path.join(args.output_dir, f\"generation_output_100p_actions.json\"),\n",
    "        \"w\",\n",
    "    ) as f:\n",
    "        json.dump(generation_output, f, indent=4) \n",
    "        \n",
    "    with open(os.path.join(args.output_dir, f\"generation_results_100p_actions.txt\"), \"w\") as f:\n",
    "        f.write(f\"Correct plans: {counter}\\n\")        \n",
    "        f.write(f\"Total plans: {total_plans}\\n\")\n",
    "        percent = counter / total_plans * 100.0\n",
    "        f.write(f\"Coverage: {percent}%\\n\")  \n",
    "        f.write(f\"Total time: {tot_time}\\n\")   \n",
    "        \n",
    "    break\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# run 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 zenotravel_p004504_hyp=hyp-6_100\n",
      "2 zenotravel_p001144_hyp=hyp-1_100\n",
      "3 zeno-travel_p03_hyp-4_full\n",
      "4 zenotravel_p005763_hyp=hyp-1_100\n",
      "5 zenotravel_p000162_hyp=hyp-7_100\n",
      "6 zeno-travel_p03_hyp-3_full\n",
      "7 zenotravel_p005406_hyp=hyp-2_100\n",
      "8 zenotravel_p004644_hyp=hyp-3_100\n",
      "9 zenotravel_p005381_hyp=hyp-5_100\n",
      "10 zenotravel_p004343_hyp=hyp-7_100\n",
      "11 zenotravel_p001113_hyp=hyp-1_100\n",
      "12 zenotravel_p003459_hyp=hyp-3_100\n",
      "13 zeno-travel_p06_hyp-4_full\n",
      "14 zeno-travel_p02_hyp-4_full\n",
      "15 zeno-travel_p05_hyp-3_full\n",
      "16 zeno-travel_p02_hyp-1_full\n",
      "17 zenotravel_p003508_hyp=hyp-5_100\n",
      "18 zeno-travel_p01_hyp-1_full\n",
      "19 zenotravel_p003670_hyp=hyp-2_100\n",
      "20 zenotravel_p004894_hyp=hyp-1_100\n",
      "21 zenotravel_p006482_hyp=hyp-4_100\n",
      "22 zenotravel_p006716_hyp=hyp-3_100\n",
      "23 zenotravel_p004142_hyp=hyp-4_100\n",
      "24 zeno-travel_p02_hyp-3_full\n",
      "25 zenotravel_p004014_hyp=hyp-3_100\n",
      "26 zenotravel_p004830_hyp=hyp-7_100\n",
      "27 zenotravel_p001035_hyp=hyp-0_100\n",
      "28 zenotravel_p006747_hyp=hyp-4_100\n",
      "29 zenotravel_p001548_hyp=hyp-1_100\n",
      "30 zenotravel_p001678_hyp=hyp-3_100\n",
      "31 zeno-travel_p07_hyp-1_full\n",
      "32 zeno-travel_p05_hyp-1_full\n",
      "33 zenotravel_p005023_hyp=hyp-1_100\n",
      "34 zenotravel_p001644_hyp=hyp-5_100\n",
      "35 zenotravel_p002853_hyp=hyp-3_100\n",
      "36 zenotravel_p003023_hyp=hyp-4_100\n",
      "37 zenotravel_p005217_hyp=hyp-5_100\n",
      "38 zenotravel_p005531_hyp=hyp-0_100\n",
      "39 zeno-travel_p03_hyp-1_full\n",
      "40 zenotravel_p003554_hyp=hyp-1_100\n",
      "41 zenotravel_p005455_hyp=hyp-0_100\n",
      "42 zeno-travel_p07_hyp-2_full\n",
      "43 zenotravel_p003538_hyp=hyp-3_100\n",
      "44 zenotravel_p006670_hyp=hyp-5_100\n",
      "45 zenotravel_p002458_hyp=hyp-3_100\n",
      "46 zeno-travel_p03_hyp-2_full\n",
      "47 zenotravel_p004992_hyp=hyp-5_100\n",
      "48 zenotravel_p004422_hyp=hyp-4_100\n",
      "49 zenotravel_p001811_hyp=hyp-3_100\n",
      "50 zenotravel_p000747_hyp=hyp-1_100\n",
      "51 zenotravel_p002575_hyp=hyp-0_100\n",
      "52 zenotravel_p005595_hyp=hyp-2_100\n",
      "53 zenotravel_p003708_hyp=hyp-3_100\n",
      "54 zenotravel_p001184_hyp=hyp-5_100\n",
      "55 zenotravel_p006306_hyp=hyp-0_100\n",
      "56 zeno-travel_p06_hyp-1_full\n",
      "57 zenotravel_p006381_hyp=hyp-2_100\n",
      "58 zenotravel_p006538_hyp=hyp-5_100\n",
      "59 zenotravel_p004185_hyp=hyp-5_100\n",
      "60 zenotravel_p006503_hyp=hyp-3_100\n",
      "61 zenotravel_p001853_hyp=hyp-0_100\n",
      "62 zeno-travel_p01_hyp-4_full\n",
      "63 zenotravel_p000212_hyp=hyp-4_100\n",
      "64 zenotravel_p001456_hyp=hyp-0_100\n",
      "65 zenotravel_p004458_hyp=hyp-1_100\n",
      "66 zenotravel_p006966_hyp=hyp-2_100\n",
      "67 zenotravel_p001503_hyp=hyp-3_100\n",
      "68 zeno-travel_p04_hyp-2_full\n",
      "69 zeno-travel_p07_hyp-4_full\n",
      "70 zeno-travel_p01_hyp-2_full\n",
      "71 zenotravel_p006674_hyp=hyp-5_100\n",
      "72 zeno-travel_p07_hyp-3_full\n",
      "73 zeno-travel_p05_hyp-2_full\n",
      "74 zeno-travel_p05_hyp-4_full\n",
      "75 zenotravel_p004680_hyp=hyp-3_100\n",
      "76 zeno-travel_p02_hyp-2_full\n",
      "77 zenotravel_p004101_hyp=hyp-5_100\n",
      "78 zenotravel_p001130_hyp=hyp-4_100\n",
      "79 zenotravel_p002381_hyp=hyp-3_100\n",
      "80 zenotravel_p001038_hyp=hyp-5_100\n",
      "81 zenotravel_p001635_hyp=hyp-5_100\n",
      "82 zenotravel_p003922_hyp=hyp-4_100\n",
      "83 zenotravel_p003366_hyp=hyp-3_100\n",
      "84 zenotravel_p006130_hyp=hyp-2_100\n",
      "85 zenotravel_p004406_hyp=hyp-6_100\n",
      "86 zeno-travel_p06_hyp-3_full\n",
      "87 zenotravel_p006561_hyp=hyp-2_100\n",
      "88 zenotravel_p003895_hyp=hyp-1_100\n",
      "89 zenotravel_p001494_hyp=hyp-0_100\n",
      "90 zenotravel_p006162_hyp=hyp-4_100\n",
      "91 zenotravel_p005162_hyp=hyp-0_100\n",
      "92 zeno-travel_p04_hyp-4_full\n",
      "93 zenotravel_p000877_hyp=hyp-9_100\n",
      "94 zeno-travel_p04_hyp-1_full\n",
      "95 zenotravel_p002102_hyp=hyp-2_100\n",
      "96 zeno-travel_p04_hyp-3_full\n",
      "97 zenotravel_p004129_hyp=hyp-5_100\n",
      "98 zeno-travel_p01_hyp-3_full\n",
      "99 zenotravel_p005953_hyp=hyp-4_100\n",
      "100 zeno-travel_p06_hyp-2_full\n"
     ]
    }
   ],
   "source": [
    "counter = 0\n",
    "last_generated = 0\n",
    "generation_output = []\n",
    "total_plans = 0\n",
    "tot_time = 0\n",
    "v=0\n",
    "\n",
    "for folder in os.listdir(dataset_dir):  \n",
    "    v+=1    \n",
    "    print(v,folder)\n",
    "    cont=0    \n",
    "    for file in os.listdir(os.path.join(dataset_dir, folder)):\n",
    "        path = os.path.join(dataset_dir, folder, file)\n",
    "        if file == \"template.pddl\":\n",
    "            state = initial_state(path)                \n",
    "        elif file == \"hyps.dat\":\n",
    "            goals = get_goals(path) \n",
    "        elif file == \"obs.dat\":\n",
    "            actions = get_actions(path)  \n",
    "        elif file == \"real_hyp.dat\":\n",
    "            real_goal = get_goals(path)   \n",
    "    state = unite_actions(\n",
    "        state,\n",
    "        list(dict_predicates_domain[domain].keys()),\n",
    "        domain,\n",
    "    )\n",
    "    state = [x.replace(\"_\", \" \") for x in state]\n",
    "    state = sorted(state)\n",
    "    state = \" \".join(state)    \n",
    "    \n",
    "    for r_goal in real_goal:\n",
    "        r_goal = unite_actions(\n",
    "            r_goal,\n",
    "            list(dict_predicates_domain[domain].keys()),\n",
    "            domain,\n",
    "        )\n",
    "        r_goal = [x.replace(\"_\", \" \") for x in r_goal]\n",
    "        r_goal = sorted(r_goal)\n",
    "        r_goal = \" \".join(r_goal)   \n",
    "        \n",
    "    prompts = []\n",
    "    prompts_tokenized = []\n",
    "    goals_sorted = []\n",
    "    for goal in goals:\n",
    "        goal = unite_actions(\n",
    "            goal,\n",
    "            list(dict_predicates_domain[domain].keys()),\n",
    "            domain,\n",
    "        )\n",
    "\n",
    "        goal = [x.replace(\"_\", \" \") for x in goal]\n",
    "        goal = sorted(goal)\n",
    "        goal = \" \".join(goal)\n",
    "        goals_sorted.append(goal)\n",
    "        prompt = state + \" <|goals|> \" + goal + \" <|actions|>\"\n",
    "        prompts.append(prompt)\n",
    "        prompt_tokenized = tokenizer(prompt, return_tensors=\"pt\", truncation=True, max_length=args.max_length)\n",
    "        prompt_tokenized = prompt_tokenized[\"input_ids\"].to(model.device)\n",
    "        prompts_tokenized.append(prompt_tokenized) \n",
    "    \n",
    "    for prompt_tokenized in prompts_tokenized:        \n",
    "        \n",
    "        with torch.inference_mode():\n",
    "            start_time = time.time()\n",
    "            generated = model.generate(\n",
    "                prompt_tokenized,\n",
    "                pad_token_id=tokenizer.eos_token_id,\n",
    "                max_length=args.max_length,\n",
    "                generation_config=generation_config,\n",
    "            )\n",
    "            end_time = time.time()\n",
    "            delta_time = end_time - start_time\n",
    "            tot_time+=delta_time          \n",
    "        \n",
    "        \n",
    "        found_true = False\n",
    "        plans = []\n",
    "        for index, output_tokenized in enumerate(generated):              \n",
    "            output = tokenizer.decode(output_tokenized)                                    \n",
    "            inputs = output.split(\"<|actions|>\")[0]            \n",
    "            plan = output.split(\"<|actions|>\")[1]\n",
    "            if \"<|endofplan|>\" in plan:        \n",
    "                plan = plan.split(\"<|endofplan|>\")[0]\n",
    "            plan = plan.replace(\"<|endofplan|>\", \"\")\n",
    "            plan = plan.replace(\"<|startofplan|>\", \"\")\n",
    "            plan = plan.replace(\"<|pad|>\", \"\")\n",
    "            p = {\"input\": inputs, \"actions\": plan}       \n",
    "            res = parse_problem(p, domain=domain) \n",
    "            metric_goals_satisfated=calculate_reward(p,domain=domain) \n",
    "            plans.append({\"plan\": plan, \"result\": res})  \n",
    "            if res[0] is True:\n",
    "                found_true = True        \n",
    "           \n",
    "        if found_true is True:\n",
    "            counter += 1            \n",
    "        \n",
    "        actions_string = \" \".join(actions)           \n",
    "       \n",
    "        if r_goal == goals_sorted[cont]:            \n",
    "            true_goal = True  \n",
    "        else:\n",
    "            true_goal = False             \n",
    "                       \n",
    "        generation_output.append(\n",
    "            {\n",
    "                \"name\": folder,\n",
    "                \"goal\": goals[cont],\n",
    "                \"input\": prompts[cont],               \n",
    "                \"true_goal\": true_goal,\n",
    "                \"actions\": actions_string,\n",
    "                \"plans\": plans, \n",
    "                \"value of the metric goals satisfated\": metric_goals_satisfated,\n",
    "                \"time\": format(delta_time, \".2f\"),\n",
    "            }\n",
    "        )           \n",
    "        cont+=1         \n",
    "        \n",
    "    total_plans+=cont \n",
    "    \n",
    "    # Save the last batch\n",
    "    with open(\n",
    "        os.path.join(args.output_dir, f\"generation_output_100p_NoAction.json\"),\n",
    "        \"w\",\n",
    "    ) as f:\n",
    "        json.dump(generation_output, f, indent=4) \n",
    "        \n",
    "    with open(os.path.join(args.output_dir, f\"generation_results_100p_NoAction.txt\"), \"w\") as f:\n",
    "        f.write(f\"Correct plans: {counter}\\n\")        \n",
    "        f.write(f\"Total plans: {total_plans}\\n\")\n",
    "        percent = counter / total_plans * 100.0\n",
    "        f.write(f\"Coverage: {percent}%\\n\")  \n",
    "        f.write(f\"Total time: {tot_time}\\n\")  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
