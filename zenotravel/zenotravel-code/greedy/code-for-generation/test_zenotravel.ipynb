{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "import re\n",
    "import torch\n",
    "from transformers.generation import (\n",
    "    StoppingCriteria,\n",
    "    StoppingCriteriaList,\n",
    "    BeamSearchScorer,\n",
    "    LogitsProcessorList,\n",
    "    MaxLengthCriteria,\n",
    ")\n",
    "from transformers import LogitsProcessor\n",
    "import numpy as np\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from typing import Optional, Union, Tuple, List\n",
    "from datasets import load_from_disk\n",
    "from tqdm import tqdm\n",
    "from transformers import GPT2LMHeadModel, GenerationConfig\n",
    "from transformers import HfArgumentParser\n",
    "import os\n",
    "import sys\n",
    "from dataclasses import dataclass, field\n",
    "from datasets import Dataset\n",
    "import pandas as pd\n",
    "import os\n",
    "import json\n",
    "import time\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Generazione con zenotravel e greedy\n",
      "### Generazione con config.json\n",
      "{\n",
      "    \"domain\": \"zenotravel\",\n",
      "    \"model_dir\": \"./zenotravel-model/\",\n",
      "    \"dataset_dir\": \"./zenotravel-dataset-tesi/\",\n",
      "    \"num_beams\": 1,\n",
      "    \"num_return_beams\": 1,\n",
      "    \"split_dataset\": \"test\",\n",
      "    \"output_dir\": \"zenotravel-generations-tesi/greedy/\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "domains = [\"zenotravel\"]\n",
    "\n",
    "for domain in domains:\n",
    "    for mode in [\"greedy\"]:\n",
    "        print(f\"### Generazione con {domain} e {mode}\")\n",
    "        path = f\"config.json\"\n",
    "        params = {\n",
    "            \"domain\": domain,\n",
    "            \"model_dir\": f\"./{domain}-model/\", \n",
    "            \"dataset_dir\": f\"./{domain}-dataset-tesi/\",\n",
    "            \"num_beams\": 1,\n",
    "            \"num_return_beams\": 1,\n",
    "            \"split_dataset\": \"test\",\n",
    "            \"output_dir\": f\"{domain}-generations-tesi/greedy/\",\n",
    "        }\n",
    "        with open(path, \"w\") as file:\n",
    "            tmp = json.dumps(params, indent=4)\n",
    "            file.write(tmp)\n",
    "        with open(path, \"r\") as file:\n",
    "            # Carica il contenuto del file JSON in una variabile\n",
    "            data = json.load(file)\n",
    "        print(\"### Generazione con \" + path)\n",
    "        print(json.dumps(data, indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class PlanGeneratorArguments:\n",
    "    domain: str = field(\n",
    "        default=\"zenotravel\",\n",
    "        metadata={\"help\": \"The domain of the problems\"},\n",
    "    )\n",
    "    model_dir: str = field(\n",
    "        default=\"output_new_finetuning_more_batch/checkpoint-258502/\",\n",
    "        metadata={\"help\": \"The model directory\"},\n",
    "    )\n",
    "    dataset_dir: str = field(\n",
    "        default=\"data/ipc/zenotravel/random_new_correct_with_invariants_and_types/\",\n",
    "        metadata={\"help\": \"The dataset directory\"},\n",
    "    )\n",
    "    add_start: bool = field(\n",
    "        default=False,\n",
    "        metadata={\"help\": \"Add the start token to the prompt\"},\n",
    "    )\n",
    "    split_dataset: str = field(\n",
    "        default=\"validation\",\n",
    "        metadata={\"help\": \"The split of the dataset to use\"},\n",
    "    )\n",
    "    output_dir: str = field(\n",
    "        default=\"output_coverage_beam_search/\",\n",
    "        metadata={\"help\": \"The output directory\"},\n",
    "    )\n",
    "    # generation parameters\n",
    "    num_beams: int = field(\n",
    "        default=1,\n",
    "        metadata={\"help\": \"The number of beams to track\"},\n",
    "    )\n",
    "    num_return_beams: int = field(\n",
    "        default=1,\n",
    "        metadata={\"help\": \"The number of beams to return\"},\n",
    "    )\n",
    "    max_length: int = field(\n",
    "        default=2048,\n",
    "        metadata={\"help\": \"The maximum length of the generated plan\"},\n",
    "    )   \n",
    "    do_sample: bool = field(\n",
    "        default=False,\n",
    "        metadata={\"help\": \"If to sample the generation\"},\n",
    "    )\n",
    "    top_p: float = field(\n",
    "        default=1.0,\n",
    "        metadata={\"help\": \"The top_p parameter for the generation\"},\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./zenotravel-dataset-tesi/ ./zenotravel-model/ zenotravel\n"
     ]
    }
   ],
   "source": [
    "# Create an instance of HfArgumentParser with your argument class\n",
    "parser = HfArgumentParser(PlanGeneratorArguments)\n",
    "\n",
    "(args,) = parser.parse_json_file(json_file=path)\n",
    "\n",
    "dataset_dir = args.dataset_dir\n",
    "model_path = args.model_dir\n",
    "domain = args.domain\n",
    "\n",
    "print(dataset_dir, model_path, domain)\n",
    "\n",
    "# check if exists\n",
    "if not os.path.exists(args.output_dir):\n",
    "    os.makedirs(args.output_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPT2LMHeadModel(\n",
       "  (transformer): GPT2Model(\n",
       "    (wte): Embedding(167, 768)\n",
       "    (wpe): Embedding(2048, 768)\n",
       "    (drop): Dropout(p=0.1, inplace=False)\n",
       "    (h): ModuleList(\n",
       "      (0-11): 12 x GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D(nf=2304, nx=768)\n",
       "          (c_proj): Conv1D(nf=768, nx=768)\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D(nf=3072, nx=768)\n",
       "          (c_proj): Conv1D(nf=768, nx=3072)\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=768, out_features=167, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "if \"ape\" in model_path:\n",
    "    model = GPT2_ape.from_pretrained(model_path)\n",
    "else:    \n",
    "    model = AutoModelForCausalLM.from_pretrained(model_path)\n",
    "model.to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation config loaded\n",
      "Model and Tokenizer loaded\n"
     ]
    }
   ],
   "source": [
    "generation_config = GenerationConfig(\n",
    "        num_beams=args.num_beams,\n",
    "        max_length=args.max_length,\n",
    "        do_sample=args.do_sample,\n",
    "        num_return_sequences=args.num_return_beams,\n",
    "        top_p=args.top_p,\n",
    ")\n",
    "print(\"Generation config loaded\")\n",
    "# print(\"Generation mode: \", generation_config.get_generation_mode()) # works only with transformers 4.40 +\n",
    "\n",
    "print(\"Model and Tokenizer loaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_actions_z = {}\n",
    "dict_predicates_z = {}\n",
    "dict_objects_z = {}\n",
    "\n",
    "dict_actions_z[\"board\"] = (\n",
    "    [\"person\", \"aircraft\", \"city\"],\n",
    "    [\"at 0 2\", \"at 1 2\"],\n",
    "    [\"in 0 1\"],\n",
    "    [\"at 0 2\"],\n",
    ")\n",
    "dict_actions_z[\"debark\"] = (\n",
    "    [\"person\", \"aircraft\", \"city\"],\n",
    "    [\"in 0 1\", \"at 1 2\"],\n",
    "    [\"at 0 2\"],\n",
    "    [\"in 0 1\"],\n",
    ")\n",
    "dict_actions_z[\"fly\"] = (\n",
    "    [\"aircraft\", \"city\", \"city\", \"flevel\", \"flevel\"],\n",
    "    [\"at 0 1\", \"fuel-level 0 3\", \"next 4 3\"],\n",
    "    [\"at 0 2\", \"fuel-level 0 4\"],\n",
    "    [\"at 0 1\", \"fuel-level 0 3\"],\n",
    ")\n",
    "dict_actions_z[\"zoom\"] = (\n",
    "    [\"aircraft\", \"city\", \"city\", \"flevel\", \"flevel\", \"flevel\"],\n",
    "    [\"at 0 1\", \"fuel-level 0 3\", \"next 4 3\", \"next 5 4\"],\n",
    "    [\"at 0 2\", \"fuel-level 0 5\"],\n",
    "    [\"at 0 1\", \"fuel-level 0 3\"],\n",
    ")\n",
    "dict_actions_z[\"refuel\"] = (\n",
    "    [\"aircraft\", \"city\", \"flevel\", \"flevel\"],\n",
    "    [\"fuel-level 0 2\", \"next 2 3\", \"at 0 1\"],\n",
    "    [\"fuel-level 0 3\"],\n",
    "    [\"fuel-level 0 2\"],\n",
    ")\n",
    "\n",
    "dict_predicates_z[\"at\"] = ([\"person\", \"aircraft\"], [\"city\"])\n",
    "dict_predicates_z[\"in\"] = ([\"person\"], [\"aircraft\"])\n",
    "dict_predicates_z[\"fuel-level\"] = ([\"flevel\"], [\"aircraft\"])\n",
    "dict_predicates_z[\"next\"] = ([\"flevel\"], [\"flevel\"])\n",
    "\n",
    "dict_predicates_z[\"aircraft\"] = [\"ob\"]\n",
    "dict_predicates_z[\"person\"] = [\"ob\"]\n",
    "dict_predicates_z[\"city\"] = [\"ob\"]\n",
    "dict_predicates_z[\"flevel\"] = [\"ob\"]\n",
    "\n",
    "dict_objects_z[\"aircraft\"] = [\"plane\"]\n",
    "dict_objects_z[\"person\"] = [\"person\"]\n",
    "dict_objects_z[\"city\"] = [\"city\"]\n",
    "dict_objects_z[\"flevel\"] = [\"fl\"]\n",
    "\n",
    "convert_action_z = {}\n",
    "convert_action_z[\"fuellevel\"] = \"fuel-level\"\n",
    "\n",
    "\n",
    "dict_actions_domain = {}\n",
    "dict_predicates_domain = {}\n",
    "dict_objects_domain = {}\n",
    "convert_action_domain = {}\n",
    "\n",
    "dict_actions_domain[\"zenotravel\"] = dict_actions_z\n",
    "dict_predicates_domain[\"zenotravel\"] = dict_predicates_z\n",
    "dict_objects_domain[\"zenotravel\"] = dict_objects_z\n",
    "convert_action_domain[\"zenotravel\"] = convert_action_z "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# funzioni gestione input ed estrazione dati"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unite_actions(input, keywords, domain, separator=\"_\"):\n",
    "\n",
    "    for conversion in convert_action_domain[domain].keys():         \n",
    "        input = input.replace(conversion, convert_action_domain[domain][conversion])\n",
    "    list_to_unite = input.split()    \n",
    "    index_actions = []\n",
    "    for idx, token in enumerate(list_to_unite):\n",
    "        if token in keywords:            \n",
    "            index_actions.append(idx)    \n",
    "    index_actions.append(len(list_to_unite))\n",
    "    new_list = []\n",
    "    for i in range(len(index_actions) - 1):        \n",
    "        new_action = \" \".join(list_to_unite[index_actions[i] : index_actions[i + 1]])        \n",
    "        new_list.append(new_action.replace(\" \", separator))\n",
    "    return new_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initial_state(path):\n",
    "    v=0\n",
    "    with open(path, \"r\") as f:         \n",
    "        righe = f.readlines()         \n",
    "              \n",
    "        inizio = False\n",
    "        state = \"\"\n",
    "\n",
    "        for riga in righe:\n",
    "            riga = riga.strip().replace(\"(\", \"\").replace(\")\", \"\")\n",
    "            if \"_100\" in path:\n",
    "                if \" - \" in riga:\n",
    "                    riga = riga.replace(\"-\", \" \").split()\n",
    "                    riga = riga[::-1]\n",
    "                    riga = \" \".join(riga)\n",
    "                    state += riga + \" \"\n",
    "            if riga == \"\":\n",
    "                inizio = False\n",
    "            if inizio:\n",
    "                state += riga + \" \"\n",
    "            if riga == \":init\":\n",
    "                inizio = True            \n",
    "\n",
    "    return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_goals(path):\n",
    "    goals = []\n",
    "    with open(path, \"r\") as f:\n",
    "        righe = f.readlines()\n",
    "        for riga in righe:\n",
    "            riga = riga.strip().replace(\"(\", \"\").replace(\")\", \"\").replace(\",\", \"\").lower()\n",
    "            goals.append(riga)\n",
    "    return goals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_actions(path):\n",
    "    actions = []\n",
    "    with open(path, \"r\") as f:\n",
    "        righe = f.readlines()\n",
    "        for riga in righe:\n",
    "            riga = riga.strip().replace(\"(\", \"\").replace(\")\", \"\").lower()\n",
    "            actions.append(riga)\n",
    "    return actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_starting_structures(plan, domain):\n",
    "\n",
    "    initial_states = (\n",
    "        plan[\"input\"].split(\"<|goals|>\")[0].strip().split(\"<|startofplan|>\")[1].strip()\n",
    "    )  \n",
    "       \n",
    "    goal_states = (\n",
    "        plan[\"input\"].split(\"<|goals|>\")[1].strip().split(\"<|actions|>\")[0].strip()\n",
    "    )\n",
    "    \n",
    "    initial_states = unite_actions(\n",
    "        initial_states, list(dict_predicates_domain[domain].keys()), domain\n",
    "    )\n",
    "    goal_states = unite_actions(\n",
    "        goal_states, list(dict_predicates_domain[domain].keys()), domain\n",
    "    )\n",
    "    if \"<|endofplan|>\" in plan[\"actions\"]:\n",
    "        actions = unite_actions(\n",
    "            plan[\"actions\"].split(\"<|endofplan|>\").strip(),\n",
    "            list(dict_actions_domain[domain].keys()),\n",
    "            domain,\n",
    "        )\n",
    "    else:\n",
    "        actions = unite_actions(\n",
    "            plan[\"actions\"], list(dict_actions_domain[domain].keys()), domain\n",
    "        )\n",
    "        \n",
    "    \n",
    "    dict_states = {}\n",
    "    dict_goals = {}\n",
    "    for init_state in initial_states:\n",
    "        dict_states[init_state] = True\n",
    "    for goal_state in goal_states:\n",
    "        if goal_state in initial_states:\n",
    "            dict_goals[goal_state] = True\n",
    "        else:\n",
    "            dict_goals[goal_state] = False    \n",
    "    return (dict_states, dict_goals, actions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rimuovi_numeri(stringa):\n",
    "    return \"\".join([i for i in stringa if not i.isdigit()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# funzioni di validità"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_goals(states, goal_states, domain):\n",
    "    all_goals_satisfied = True\n",
    "    goals_unsatisfied_list = []\n",
    "    goals_unsatisfied_list_nonumber = []\n",
    "    # print(goal_states)\n",
    "    for goal in goal_states.keys():\n",
    "        # print(\"Analizzo il goal \" + goal)\n",
    "        if goal not in states.keys():\n",
    "            goal_states[goal] = False\n",
    "            all_goals_satisfied = False\n",
    "            goals_unsatisfied_list.append(goal)\n",
    "            goals_unsatisfied_list_nonumber.append(rimuovi_numeri(goal))\n",
    "            # print(\"Il mio goal non è negli stati visti\")\n",
    "        elif states[goal] is False:\n",
    "            goal_states[goal] = False\n",
    "            all_goals_satisfied = False\n",
    "            goals_unsatisfied_list.append(goal)\n",
    "            goals_unsatisfied_list_nonumber.append(rimuovi_numeri(goal))\n",
    "            # print(\"Il mio goal è negli stati visti falso\")\n",
    "        else:\n",
    "            goal_states[goal] = True\n",
    "            # print(\"Il mio goal è negli stati visti vero\")\n",
    "    if all_goals_satisfied is True:\n",
    "        return (True, goal_states, \"goals_succesfull\")\n",
    "    else:\n",
    "        return (\n",
    "            False,\n",
    "            goal_states,\n",
    "            \"goals_not_succesfull\",\n",
    "            goals_unsatisfied_list_nonumber,\n",
    "            goals_unsatisfied_list,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def execute_action(states, action, domain):\n",
    "    # Return a Tuple\n",
    "    # in the first position the result True, False\n",
    "    # in the second position the next state if result is True or the current state if it is False\n",
    "    # in the third position the motivation of the wrong execution\n",
    "    # split my action, on position 0 the action, then the objects\n",
    "    # print(action)\n",
    "    splitted_action = action.split(\"_\")[0]  # prendo il nome della mia azione\n",
    "    try:\n",
    "        action_parameter = dict_actions_domain[domain][\n",
    "            splitted_action\n",
    "        ]  # verifico che l'azione esiste\n",
    "    except:\n",
    "        action_parameter = None\n",
    "    if action_parameter is None:\n",
    "        return (False, states, \"action_name_wrong\", splitted_action, action, \"\")\n",
    "    splitted_objects = action.split(\"_\")[\n",
    "        1:\n",
    "    ]  # ottengo il nome dei miei oggetti definiti nel mio problema\n",
    "    action_objects = action_parameter[0]  # ottengo gli oggetti accettati dall'azione\n",
    "    if len(action_objects) == len(\n",
    "        splitted_objects\n",
    "    ):  # verifico che gli oggetti siano in egual numero rispetto a quanti ne richiede la mia azione\n",
    "        for i in range(0, len(action_objects)):  # scorro i miei oggetti\n",
    "            obj_nonumber = \"\".join(\n",
    "                [j for j in splitted_objects[i] if not j.isdigit()]\n",
    "            )  # calcolo il mio nome dell'oggetto senza tener conto dei numeri\n",
    "            if (\n",
    "                obj_nonumber not in dict_objects_domain[domain][action_objects[i]]\n",
    "            ):  # verifico che l'oggetto si trovi nella lista di nomi possibili associata alla descrizione dell'azione\n",
    "                # print(\"Errore: \" + obj_nonumber + \" non è un oggetto valido per \" + action_objects[i])\n",
    "                # print(\"Gli oggetti validi sono: \" + str(dict_objects_domain[domain][action_objects[i]]))\n",
    "                return (\n",
    "                    False,\n",
    "                    states,\n",
    "                    \"object_name_wrong\",\n",
    "                    splitted_action,\n",
    "                    obj_nonumber,\n",
    "                    splitted_objects[i],\n",
    "                )\n",
    "    else:\n",
    "        return (\n",
    "            False,\n",
    "            states,\n",
    "            \"object_number_wrong\",\n",
    "            splitted_action,\n",
    "            len(action_objects),\n",
    "            len(splitted_objects),\n",
    "        )\n",
    "\n",
    "    action_prec = action_parameter[1]  # prendo le precondizioni della mia azione\n",
    "    violed_precondtion = False\n",
    "    violed_preconditions_list = []\n",
    "    violed_preconditions_list_nonumber = []\n",
    "    for prec in action_prec:  # scorro le mie precondizioni\n",
    "        prec_list = prec.split(\" \")\n",
    "        prec_parametrized = \"\" + prec_list[0]  # metto il mio predicato\n",
    "        for obj in prec_list[1:]:  # scorro gli oggetti della mia precondizione\n",
    "            prec_parametrized = (\n",
    "                prec_parametrized + \"_\" + splitted_objects[int(obj)]\n",
    "            )  # sostituisco gli oggetti generici ai miei oggetti del problema\n",
    "        if (\n",
    "            prec_parametrized not in states.keys()\n",
    "        ):  # controllo se la mia precondizione esiste come chiave del dizionario (se non esiste non è vera)\n",
    "            violed_precondtion = True\n",
    "            violed_preconditions_list.append(prec_parametrized)\n",
    "            violed_preconditions_list_nonumber.append(rimuovi_numeri(prec_parametrized))\n",
    "        elif (\n",
    "            states[prec_parametrized] is False\n",
    "        ):  # controllo che la mia precondizione sia vera per eseguire l'azione\n",
    "            violed_precondtion = True\n",
    "            violed_preconditions_list.append(prec_parametrized)\n",
    "            violed_preconditions_list_nonumber.append(rimuovi_numeri(prec_parametrized))\n",
    "        else:\n",
    "            pass\n",
    "    if violed_precondtion is True:\n",
    "        return (\n",
    "            False,\n",
    "            states,\n",
    "            \"violed_preconditions\",\n",
    "            violed_preconditions_list_nonumber,\n",
    "            violed_preconditions_list,\n",
    "            splitted_action,\n",
    "        )\n",
    "\n",
    "    # eseguo gli effetti negativi\n",
    "    action_neg = action_parameter[3]  # prendo i miei effetti negativi\n",
    "    for neg in action_neg:  # li scorro\n",
    "        neg_list = neg.split(\" \")\n",
    "        neg_parametrized = \"\" + neg_list[0]  # ottengo il mio predicato\n",
    "        for obj in neg_list[1:]:  # per ogni oggetto (rappresentato come indice)\n",
    "            neg_parametrized = (\n",
    "                neg_parametrized + \"_\" + splitted_objects[int(obj)]\n",
    "            )  # vado a sostituirlo col corrispettivo dell'azione in corso\n",
    "        states[neg_parametrized] = False  # cambio il valore nei miei stati\n",
    "        # print(\"ho reso falso \" + neg_parametrized)\n",
    "\n",
    "    # eseguo gli effetti additivi\n",
    "    action_plus = action_parameter[2]  # prendo i miei effetti additivi\n",
    "    for plus in action_plus:  # li scorro\n",
    "        plus_list = plus.split(\" \")\n",
    "        plus_parametrized = \"\" + plus_list[0]  # ottengo il mio predicato\n",
    "        for obj in plus_list[1:]:  # per ogni oggetto (rappresentato come indice)\n",
    "            plus_parametrized = (\n",
    "                plus_parametrized + \"_\" + splitted_objects[int(obj)]\n",
    "            )  # vado a sostituirlo col corrispettivo dell'azione in corso\n",
    "        states[plus_parametrized] = True  # cambio il valore nei miei stati\n",
    "        # print(\"ho reso vero \" + plus_parametrized)\n",
    "\n",
    "    return (True, states, \"action_succesfull\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_violated_preconditions(plan, domain):\n",
    "    init_structures = create_starting_structures(plan, domain)\n",
    "    init_state = init_structures[0]\n",
    "    goal_state = init_structures[1]\n",
    "    actions = init_structures[2]\n",
    "    if len(actions) == 0 and len(plan[\"actions\"]) != 0:\n",
    "        return True  # Il modello ha generato i token iniziali diversi da azioni (parole a caso)\n",
    "    # print(\"Actions \", actions)\n",
    "    result_goals = check_goals(init_state, goal_state, domain)\n",
    "    state = init_state\n",
    "    for action in actions:\n",
    "        result = execute_action(state, action, domain)\n",
    "        # print(\"Res action \", result)\n",
    "        if result[0] is True:\n",
    "            state = result[1]\n",
    "        else:\n",
    "            error_type = result[2]\n",
    "            if error_type == \"object_name_wrong\":\n",
    "                return True\n",
    "            elif error_type == \"object_number_wrong\":\n",
    "                if result[4] > result[5]:\n",
    "                    return False\n",
    "                else:\n",
    "                    return True\n",
    "            elif error_type == \"violed_preconditions\":\n",
    "                return True\n",
    "            elif error_type == \"action_name_wrong\":\n",
    "                return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# funzione calcolo reward "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_reward(plan, domain):    \n",
    "  \n",
    "    init_structures = create_starting_structures(plan, domain)\n",
    "    init_state = init_structures[0]\n",
    "    goal_state = init_structures[1]\n",
    "    actions = init_structures[2]\n",
    "\n",
    "    start = time.time()\n",
    "\n",
    "    result_goals = check_goals(init_state, goal_state, domain)\n",
    "    if result_goals[0] is True:\n",
    "        return 1\n",
    "    else:\n",
    "        pass\n",
    "    state = init_state\n",
    "    j = 0\n",
    "    for action in actions:\n",
    "        start_act = time.time()\n",
    "        result = execute_action(state, action, domain)\n",
    "        if result[0] is True:\n",
    "            # print(result[2])\n",
    "            state = result[1]\n",
    "            result_goals = check_goals(state, goal_state, domain)\n",
    "            if result_goals[0] is True:\n",
    "                return 1\n",
    "            else:\n",
    "                pass\n",
    "                # print(result_goals[2])\n",
    "        else:\n",
    "            result_goals = check_goals(state, goal_state, domain)\n",
    "            goals_satisfied = result_goals[1]\n",
    "            count = 0\n",
    "            n_goals = len(goals_satisfied.keys())\n",
    "            for goal in goals_satisfied.keys():\n",
    "                if goals_satisfied[goal] is True:\n",
    "                    count += 1\n",
    "            if check_violated_preconditions(plan, domain) is True:\n",
    "                return (count / n_goals) - 1\n",
    "            else:\n",
    "                return count / n_goals\n",
    "        j = j + 1\n",
    "        end_act = time.time()\n",
    "        # print(\"Ho impiegato per fare una azione: \" + str(end_act-start_act))\n",
    "\n",
    "    number_missing_actions = len(actions) - j\n",
    "    end = time.time()\n",
    "    # print(\"Ho impiegato \" + str(end-start))\n",
    "    goals_satisfied = result_goals[1]\n",
    "    count = 0\n",
    "    n_goals = len(goals_satisfied.keys())\n",
    "    for goal in goals_satisfied.keys():\n",
    "        if goals_satisfied[goal] is True:\n",
    "            count += 1\n",
    "    return count / n_goals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# funzione base che viene chiamata per singolo piano per controllare validità e riportare tutti i dati estratti"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_problem(plan, domain):    \n",
    "   \n",
    "            \n",
    "    init_structures = create_starting_structures(plan, domain) # riporta i dizionari dei fluenti iniziali e dei fluenti obiettivo e l'inisieme delle azioni generate\n",
    "    init_state = init_structures[0]  # dizionario con tutti i fluenti iniziali con assocciato il valore true\n",
    "    goal_state = init_structures[1]  # dizionario con i fluenti obiettivo con associato il valore true o false in base ai fluenti iniziali\n",
    "    actions = init_structures[2]     # vettore contenente le azioni generate da planGPT\n",
    "    \n",
    "    start = time.time()\n",
    "\n",
    "    result_goals = check_goals(init_state, goal_state, domain)   \n",
    "        \n",
    "    if result_goals[0] is True:\n",
    "        return (result_goals[0], result_goals[1], result_goals[2], len(actions))\n",
    "        # print(result_goals[2])\n",
    "    else:\n",
    "        pass\n",
    "        # print(result_goals[2])\n",
    "\n",
    "    state = init_state    \n",
    "    j = 0\n",
    "    for action in actions:\n",
    "        start_act = time.time()\n",
    "        result = execute_action(state, action, domain)\n",
    "        if result[0] is True:\n",
    "            # print(result[2])\n",
    "            state = result[1]\n",
    "            result_goals = check_goals(state, goal_state, domain)\n",
    "            if result_goals[0] is True:\n",
    "                # print(result_goals[2])\n",
    "                j = j + 1\n",
    "                break\n",
    "            else:\n",
    "                pass\n",
    "                # print(result_goals[2])\n",
    "        else:\n",
    "            result_goals = check_goals(state, goal_state, domain)\n",
    "            return (\n",
    "                result[0],\n",
    "                result_goals[1],\n",
    "                result[2],\n",
    "                result[3],\n",
    "                result[4],\n",
    "                result[5],\n",
    "                j,\n",
    "            )\n",
    "            # print(result[2])\n",
    "            # print(result[1])\n",
    "            break\n",
    "        j = j + 1\n",
    "        end_act = time.time()\n",
    "        # print(\"Ho impiegato per fare una azione: \" + str(end_act-start_act))\n",
    "\n",
    "    number_missing_actions = len(actions) - j\n",
    "    end = time.time()\n",
    "    # print(\"Ho impiegato \" + str(end-start))\n",
    "    return (result_goals[0], result_goals[1], result_goals[2], number_missing_actions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Approccio Online: creazione piani"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n"
     ]
    }
   ],
   "source": [
    "counter = 0\n",
    "last_generated = 0\n",
    "generation_output = []\n",
    "total_plans = 0\n",
    "tot_time = 0\n",
    "tot_skip = 0\n",
    "v=0\n",
    "\n",
    "for folder in os.listdir(dataset_dir):   \n",
    "    v+=1\n",
    "    print(v, folder)\n",
    "    cont=0\n",
    "    cont_action=0\n",
    "    for file in os.listdir(os.path.join(dataset_dir, folder)):\n",
    "        path = os.path.join(dataset_dir, folder, file)\n",
    "        if file == \"template.pddl\":\n",
    "            state = initial_state(path)                \n",
    "        elif file == \"hyps.dat\":\n",
    "            goals = get_goals(path) \n",
    "        elif file == \"obs.dat\":\n",
    "            actions = get_actions(path)  \n",
    "        elif file == \"real_hyp.dat\":\n",
    "            real_goal = get_goals(path)\n",
    "   \n",
    "    state = unite_actions(\n",
    "        state,\n",
    "        list(dict_predicates_domain[domain].keys()),\n",
    "        domain,\n",
    "    )\n",
    "    state = [x.replace(\"_\", \" \") for x in state]\n",
    "    state = sorted(state)\n",
    "    state = \" \".join(state)    \n",
    "    \n",
    "    for r_goal in real_goal:\n",
    "        r_goal = unite_actions(\n",
    "            r_goal,\n",
    "            list(dict_predicates_domain[domain].keys()),\n",
    "            domain,\n",
    "        )\n",
    "        r_goal = [x.replace(\"_\", \" \") for x in r_goal]\n",
    "        r_goal = sorted(r_goal)\n",
    "        r_goal = \" \".join(r_goal)\n",
    "    \n",
    "    prompts = []\n",
    "    prompts_tokenized = []\n",
    "    goals_sorted = []\n",
    "    for goal in goals:\n",
    "        goal = unite_actions(\n",
    "            goal,\n",
    "            list(dict_predicates_domain[domain].keys()),\n",
    "            domain,\n",
    "        )\n",
    "\n",
    "        goal = [x.replace(\"_\", \" \") for x in goal]\n",
    "        goal = sorted(goal)\n",
    "        goal = \" \".join(goal)\n",
    "        goals_sorted.append(goal)\n",
    "        prompt = state + \" <|goals|> \" + goal + \" <|actions|>\"\n",
    "        prompts.append(prompt)\n",
    "        prompt_tokenized = tokenizer(prompt, return_tensors=\"pt\", truncation=True, max_length=args.max_length)\n",
    "        prompt_tokenized = prompt_tokenized[\"input_ids\"].to(model.device)\n",
    "        prompts_tokenized.append(prompt_tokenized)\n",
    "        for action in actions:            \n",
    "            prompt = prompt + action + \" \"    \n",
    "            prompts.append(prompt)\n",
    "            prompt_tokenized = tokenizer(prompt, return_tensors=\"pt\", truncation=True, max_length=args.max_length)\n",
    "            prompt_tokenized = prompt_tokenized[\"input_ids\"].to(model.device)\n",
    "            prompts_tokenized.append(prompt_tokenized)    \n",
    "            \n",
    "    skip_number=0\n",
    "    for prompt_tokenized in prompts_tokenized:   \n",
    "        if skip_number>0:            \n",
    "            skip_number-=1 \n",
    "        else:            \n",
    "            with torch.inference_mode():                \n",
    "                start_time = time.time()\n",
    "                generated = model.generate(\n",
    "                    prompt_tokenized,\n",
    "                    pad_token_id=tokenizer.eos_token_id,\n",
    "                    max_length=args.max_length,\n",
    "                    generation_config=generation_config,\n",
    "                )\n",
    "                end_time = time.time()\n",
    "                delta_time = end_time - start_time\n",
    "                tot_time+=delta_time\n",
    "                \n",
    "            found_true = False\n",
    "            plans = []\n",
    "            for index, output_tokenized in enumerate(generated):\n",
    "                output = tokenizer.decode(output_tokenized)                 \n",
    "                inputs = output.split(\"<|actions|>\")[0]\n",
    "                plan = output.split(\"<|actions|>\")[1]\n",
    "                if \"<|endofplan|>\" in plan:        \n",
    "                    plan = plan.split(\"<|endofplan|>\")[0]\n",
    "                plan = plan.replace(\"<|endofplan|>\", \"\")\n",
    "                plan = plan.replace(\"<|startofplan|>\", \"\")\n",
    "                plan = plan.replace(\"<|pad|>\", \"\")\n",
    "                p = {\"input\": inputs, \"actions\": plan}       \n",
    "                res = parse_problem(p, domain=domain)   \n",
    "                metric_goals_satisfated=calculate_reward(p,domain=domain)   \n",
    "                plans.append({\"plan\": plan, \"result\": res})  \n",
    "                if res[0] is True:\n",
    "                    found_true = True\n",
    "                \n",
    "            if found_true is True:\n",
    "                counter += 1            \n",
    "            \n",
    "            actions_string = \" \".join(actions) \n",
    "            \n",
    "            ## controllo se il piano generato  è uguale alle azioni da aggiungere            \n",
    "            \n",
    "            # if plans[0][\"plan\"].strip() == actions_string:  \n",
    "            #     # print(plans[0][\"result\"][0])  \n",
    "            #     # print(goals[cont])        \n",
    "            #     skip_number = len(actions)-cont_action\n",
    "            #     tot_skip+=skip_number\n",
    "            #     if skip_number>0:\n",
    "            #         total_plans+=(cont_action+1)\n",
    "            #     if plans[0][\"result\"][0]:\n",
    "            #         counter+=skip_number \n",
    "            \n",
    "            if r_goal == goals_sorted[cont]:  \n",
    "                true_goal = True                        \n",
    "            else:\n",
    "                true_goal = False\n",
    "                \n",
    "            generation_output.append(\n",
    "                {\n",
    "                    \"name\": folder,\n",
    "                    \"goal\": goals[cont],\n",
    "                    \"input\": prompts[cont], #cont or cont_action\n",
    "                    \"action\": prompts[cont_action].split(\"<|actions|>\")[1],\n",
    "                    \"true_goal\": true_goal,\n",
    "                    \"actions\": actions_string,\n",
    "                    \"plans\": plans,\n",
    "                    \"value of the metric goals satisfated\": metric_goals_satisfated,\n",
    "                    #\"actions\": actions,\n",
    "                    \"time\": format(delta_time, \".2f\"),\n",
    "                }\n",
    "            )  \n",
    "            cont_action+=1\n",
    "            if cont_action > len(actions):            \n",
    "                total_plans+=cont_action            \n",
    "                cont_action=0\n",
    "                cont+=1 \n",
    "            \n",
    "            \n",
    "            if skip_number>0:\n",
    "                cont_action=0\n",
    "                cont+=1            \n",
    "    \n",
    "    \n",
    "    # Save the last batch\n",
    "    with open(\n",
    "        os.path.join(args.output_dir, f\"generation_output_100p_actions_NewTest.json\"),\n",
    "        \"w\",\n",
    "    ) as f:\n",
    "        json.dump(generation_output, f, indent=4) \n",
    "        \n",
    "    with open(os.path.join(args.output_dir, f\"generation_results_100p_actions_NewTest.txt\"), \"w\") as f:\n",
    "        f.write(f\"Correct plans: {counter}\\n\")\n",
    "        f.write(f\"Skip plan generation: {tot_skip}\\n\")\n",
    "        f.write(f\"Total plans: {total_plans}\\n\")\n",
    "        percent = counter / total_plans * 100.0\n",
    "        f.write(f\"Coverage: {percent}%\\n\")  \n",
    "        f.write(f\"Total time: {tot_time}\\n\")\n",
    "            \n",
    "    break\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Approccio Offline: creazione piani"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 zenotravel_p004504_hyp=hyp-6_100\n",
      "2 zenotravel_p001144_hyp=hyp-1_100\n",
      "3 zeno-travel_p03_hyp-4_full\n",
      "4 zenotravel_p005763_hyp=hyp-1_100\n",
      "5 zenotravel_p000162_hyp=hyp-7_100\n",
      "6 zeno-travel_p03_hyp-3_full\n",
      "7 zenotravel_p005406_hyp=hyp-2_100\n",
      "8 zenotravel_p004644_hyp=hyp-3_100\n",
      "9 zenotravel_p005381_hyp=hyp-5_100\n",
      "10 zenotravel_p004343_hyp=hyp-7_100\n",
      "11 zenotravel_p001113_hyp=hyp-1_100\n",
      "12 zenotravel_p003459_hyp=hyp-3_100\n",
      "13 zeno-travel_p06_hyp-4_full\n",
      "14 zeno-travel_p02_hyp-4_full\n",
      "15 zeno-travel_p05_hyp-3_full\n",
      "16 zeno-travel_p02_hyp-1_full\n",
      "17 zenotravel_p003508_hyp=hyp-5_100\n",
      "18 zeno-travel_p01_hyp-1_full\n",
      "19 zenotravel_p003670_hyp=hyp-2_100\n",
      "20 zenotravel_p004894_hyp=hyp-1_100\n",
      "21 zenotravel_p006482_hyp=hyp-4_100\n",
      "22 zenotravel_p006716_hyp=hyp-3_100\n",
      "23 zenotravel_p004142_hyp=hyp-4_100\n",
      "24 zeno-travel_p02_hyp-3_full\n",
      "25 zenotravel_p004014_hyp=hyp-3_100\n",
      "26 zenotravel_p004830_hyp=hyp-7_100\n",
      "27 zenotravel_p001035_hyp=hyp-0_100\n",
      "28 zenotravel_p006747_hyp=hyp-4_100\n",
      "29 zenotravel_p001548_hyp=hyp-1_100\n",
      "30 zenotravel_p001678_hyp=hyp-3_100\n",
      "31 zeno-travel_p07_hyp-1_full\n",
      "32 zeno-travel_p05_hyp-1_full\n",
      "33 zenotravel_p005023_hyp=hyp-1_100\n",
      "34 zenotravel_p001644_hyp=hyp-5_100\n",
      "35 zenotravel_p002853_hyp=hyp-3_100\n",
      "36 zenotravel_p003023_hyp=hyp-4_100\n",
      "37 zenotravel_p005217_hyp=hyp-5_100\n",
      "38 zenotravel_p005531_hyp=hyp-0_100\n",
      "39 zeno-travel_p03_hyp-1_full\n",
      "40 zenotravel_p003554_hyp=hyp-1_100\n",
      "41 zenotravel_p005455_hyp=hyp-0_100\n",
      "42 zeno-travel_p07_hyp-2_full\n",
      "43 zenotravel_p003538_hyp=hyp-3_100\n",
      "44 zenotravel_p006670_hyp=hyp-5_100\n",
      "45 zenotravel_p002458_hyp=hyp-3_100\n",
      "46 zeno-travel_p03_hyp-2_full\n",
      "47 zenotravel_p004992_hyp=hyp-5_100\n",
      "48 zenotravel_p004422_hyp=hyp-4_100\n",
      "49 zenotravel_p001811_hyp=hyp-3_100\n",
      "50 zenotravel_p000747_hyp=hyp-1_100\n",
      "51 zenotravel_p002575_hyp=hyp-0_100\n",
      "52 zenotravel_p005595_hyp=hyp-2_100\n",
      "53 zenotravel_p003708_hyp=hyp-3_100\n",
      "54 zenotravel_p001184_hyp=hyp-5_100\n",
      "55 zenotravel_p006306_hyp=hyp-0_100\n",
      "56 zeno-travel_p06_hyp-1_full\n",
      "57 zenotravel_p006381_hyp=hyp-2_100\n",
      "58 zenotravel_p006538_hyp=hyp-5_100\n",
      "59 zenotravel_p004185_hyp=hyp-5_100\n",
      "60 zenotravel_p006503_hyp=hyp-3_100\n",
      "61 zenotravel_p001853_hyp=hyp-0_100\n",
      "62 zeno-travel_p01_hyp-4_full\n",
      "63 zenotravel_p000212_hyp=hyp-4_100\n",
      "64 zenotravel_p001456_hyp=hyp-0_100\n",
      "65 zenotravel_p004458_hyp=hyp-1_100\n",
      "66 zenotravel_p006966_hyp=hyp-2_100\n",
      "67 zenotravel_p001503_hyp=hyp-3_100\n",
      "68 zeno-travel_p04_hyp-2_full\n",
      "69 zeno-travel_p07_hyp-4_full\n",
      "70 zeno-travel_p01_hyp-2_full\n",
      "71 zenotravel_p006674_hyp=hyp-5_100\n",
      "72 zeno-travel_p07_hyp-3_full\n",
      "73 zeno-travel_p05_hyp-2_full\n",
      "74 zeno-travel_p05_hyp-4_full\n",
      "75 zenotravel_p004680_hyp=hyp-3_100\n",
      "76 zeno-travel_p02_hyp-2_full\n",
      "77 zenotravel_p004101_hyp=hyp-5_100\n",
      "78 zenotravel_p001130_hyp=hyp-4_100\n",
      "79 zenotravel_p002381_hyp=hyp-3_100\n",
      "80 zenotravel_p001038_hyp=hyp-5_100\n",
      "81 zenotravel_p001635_hyp=hyp-5_100\n",
      "82 zenotravel_p003922_hyp=hyp-4_100\n",
      "83 zenotravel_p003366_hyp=hyp-3_100\n",
      "84 zenotravel_p006130_hyp=hyp-2_100\n",
      "85 zenotravel_p004406_hyp=hyp-6_100\n",
      "86 zeno-travel_p06_hyp-3_full\n",
      "87 zenotravel_p006561_hyp=hyp-2_100\n",
      "88 zenotravel_p003895_hyp=hyp-1_100\n",
      "89 zenotravel_p001494_hyp=hyp-0_100\n",
      "90 zenotravel_p006162_hyp=hyp-4_100\n",
      "91 zenotravel_p005162_hyp=hyp-0_100\n",
      "92 zeno-travel_p04_hyp-4_full\n",
      "93 zenotravel_p000877_hyp=hyp-9_100\n",
      "94 zeno-travel_p04_hyp-1_full\n",
      "95 zenotravel_p002102_hyp=hyp-2_100\n",
      "96 zeno-travel_p04_hyp-3_full\n",
      "97 zenotravel_p004129_hyp=hyp-5_100\n",
      "98 zeno-travel_p01_hyp-3_full\n",
      "99 zenotravel_p005953_hyp=hyp-4_100\n",
      "100 zeno-travel_p06_hyp-2_full\n"
     ]
    }
   ],
   "source": [
    "counter = 0\n",
    "last_generated = 0\n",
    "generation_output = []\n",
    "total_plans = 0\n",
    "tot_time = 0\n",
    "v=0\n",
    "\n",
    "for folder in os.listdir(dataset_dir):  \n",
    "    v+=1    \n",
    "    print(v,folder)\n",
    "    cont=0    \n",
    "    for file in os.listdir(os.path.join(dataset_dir, folder)):\n",
    "        path = os.path.join(dataset_dir, folder, file)\n",
    "        if file == \"template.pddl\":\n",
    "            state = initial_state(path)                \n",
    "        elif file == \"hyps.dat\":\n",
    "            goals = get_goals(path) \n",
    "        elif file == \"obs.dat\":\n",
    "            actions = get_actions(path)  \n",
    "        elif file == \"real_hyp.dat\":\n",
    "            real_goal = get_goals(path)   \n",
    "    state = unite_actions(\n",
    "        state,\n",
    "        list(dict_predicates_domain[domain].keys()),\n",
    "        domain,\n",
    "    )\n",
    "    state = [x.replace(\"_\", \" \") for x in state]\n",
    "    state = sorted(state)\n",
    "    state = \" \".join(state)    \n",
    "    \n",
    "    for r_goal in real_goal:\n",
    "        r_goal = unite_actions(\n",
    "            r_goal,\n",
    "            list(dict_predicates_domain[domain].keys()),\n",
    "            domain,\n",
    "        )\n",
    "        r_goal = [x.replace(\"_\", \" \") for x in r_goal]\n",
    "        r_goal = sorted(r_goal)\n",
    "        r_goal = \" \".join(r_goal)   \n",
    "        \n",
    "    prompts = []\n",
    "    prompts_tokenized = []\n",
    "    goals_sorted = []\n",
    "    for goal in goals:\n",
    "        goal = unite_actions(\n",
    "            goal,\n",
    "            list(dict_predicates_domain[domain].keys()),\n",
    "            domain,\n",
    "        )\n",
    "\n",
    "        goal = [x.replace(\"_\", \" \") for x in goal]\n",
    "        goal = sorted(goal)\n",
    "        goal = \" \".join(goal)\n",
    "        goals_sorted.append(goal)\n",
    "        prompt = state + \" <|goals|> \" + goal + \" <|actions|>\"\n",
    "        prompts.append(prompt)\n",
    "        prompt_tokenized = tokenizer(prompt, return_tensors=\"pt\", truncation=True, max_length=args.max_length)\n",
    "        prompt_tokenized = prompt_tokenized[\"input_ids\"].to(model.device)\n",
    "        prompts_tokenized.append(prompt_tokenized) \n",
    "    \n",
    "    for prompt_tokenized in prompts_tokenized:        \n",
    "        \n",
    "        with torch.inference_mode():\n",
    "            start_time = time.time()\n",
    "            generated = model.generate(\n",
    "                prompt_tokenized,\n",
    "                pad_token_id=tokenizer.eos_token_id,\n",
    "                max_length=args.max_length,\n",
    "                generation_config=generation_config,\n",
    "            )\n",
    "            end_time = time.time()\n",
    "            delta_time = end_time - start_time\n",
    "            tot_time+=delta_time\n",
    "            \n",
    "        found_true = False\n",
    "        plans = []\n",
    "        for index, output_tokenized in enumerate(generated):            \n",
    "            output = tokenizer.decode(output_tokenized)                          \n",
    "            inputs = output.split(\"<|actions|>\")[0]\n",
    "            plan = output.split(\"<|actions|>\")[1]\n",
    "            if \"<|endofplan|>\" in plan:        \n",
    "                plan = plan.split(\"<|endofplan|>\")[0]\n",
    "            plan = plan.replace(\"<|endofplan|>\", \"\")\n",
    "            plan = plan.replace(\"<|startofplan|>\", \"\")\n",
    "            plan = plan.replace(\"<|pad|>\", \"\")\n",
    "            p = {\"input\": inputs, \"actions\": plan}       \n",
    "            res = parse_problem(p, domain=domain) \n",
    "            metric_goals_satisfated=calculate_reward(p,domain=domain) \n",
    "            plans.append({\"plan\": plan, \"result\": res})  \n",
    "            if res[0] is True:\n",
    "                found_true = True\n",
    "            \n",
    "        if found_true is True:\n",
    "            counter += 1            \n",
    "        \n",
    "        actions_string = \" \".join(actions)   \n",
    "        \n",
    "       \n",
    "        if r_goal == goals_sorted[cont]:            \n",
    "            true_goal = True  \n",
    "        else:\n",
    "            true_goal = False \n",
    "            \n",
    "                       \n",
    "        generation_output.append(\n",
    "            {\n",
    "                \"name\": folder,\n",
    "                \"goal\": goals[cont],\n",
    "                \"input\": prompts[cont],               \n",
    "                \"true_goal\": true_goal,\n",
    "                \"actions\": actions_string,\n",
    "                \"plans\": plans, \n",
    "                \"value of the metric goals satisfated\": metric_goals_satisfated,\n",
    "                \"time\": format(delta_time, \".2f\"),\n",
    "            }\n",
    "        ) \n",
    "          \n",
    "        cont+=1 \n",
    "        \n",
    "        \n",
    "    total_plans+=cont \n",
    "    \n",
    "    # Save the last batch\n",
    "    with open(\n",
    "        os.path.join(args.output_dir, f\"generation_output_100p_NewTest.json\"),\n",
    "        \"w\",\n",
    "    ) as f:\n",
    "        json.dump(generation_output, f, indent=4) \n",
    "        \n",
    "    with open(os.path.join(args.output_dir, f\"generation_results_100p_NewTest.txt\"), \"w\") as f:\n",
    "        f.write(f\"Correct plans: {counter}\\n\")        \n",
    "        f.write(f\"Total plans: {total_plans}\\n\")\n",
    "        percent = counter / total_plans * 100.0\n",
    "        f.write(f\"Coverage: {percent}%\\n\")  \n",
    "        f.write(f\"Total time: {tot_time}\\n\")       \n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
